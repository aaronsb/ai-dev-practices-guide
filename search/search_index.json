{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AI Coding Agent Practices","text":"<p>Welcome to the AI Coding Agent Practices documentation. This site provides guidance on common antipatterns and best practices when working with AI coding assistants.</p>"},{"location":"#what-youll-find-here","title":"What You'll Find Here","text":"<p>This documentation is organized into two main sections:</p>"},{"location":"#antipatterns","title":"Antipatterns","text":"<p>Common problematic patterns to watch for when working with AI coding assistants, and practical strategies to address them:</p> <ul> <li>Premature Architecture Complexity</li> <li>Test-Driven Design Misapplication</li> <li>Purpose Drift During Refactoring</li> <li>Library and Framework Reinvention</li> <li>Failure to Separate Concerns</li> </ul>"},{"location":"#best-practices","title":"Best Practices","text":"<p>Guidelines and patterns for effective AI-assisted coding:</p> <ul> <li>Managing Code Complexity</li> <li>Factory Pattern Implementation</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>If you're new to working with AI coding assistants, we recommend starting with the Antipatterns Overview to understand common pitfalls, followed by the best practices section to learn effective strategies for AI collaboration.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>This is a living document. If you have suggestions for improvements or additional patterns to document, please feel free to contribute by submitting a pull request to our GitHub repository.</p>"},{"location":"antipatterns/","title":"AI Coding Assistant Antipatterns","text":"<p>Common problematic patterns to watch for when working with AI coding assistants, and practical strategies to address them.</p>"},{"location":"antipatterns/#quick-reference-guide","title":"Quick Reference Guide","text":"<ol> <li> <p>Premature Architecture Complexity - Creating overly complex architectures before requirements are clear</p> </li> <li> <p>Test-Driven Design Misapplication - Following test patterns blindly instead of designing from first principles</p> </li> <li> <p>Purpose Drift During Refactoring - Losing sight of original goals during continuous refactoring</p> </li> <li> <p>Library and Framework Reinvention - Reimplementing functionality already available in established libraries</p> </li> <li> <p>Failure to Separate Concerns - Mixing different responsibilities within the same components</p> </li> </ol>"},{"location":"antipatterns/#general-strategies","title":"General Strategies","text":"<p>When working with AI coding assistants:</p> <p>While each antipattern has specific remediation approaches, several general strategies apply across all patterns:</p> <ol> <li>Start with clear requirements and constraints</li> <li>Be explicit about what is needed and what isn't</li> <li> <p>Define scope boundaries before discussing architecture</p> </li> <li> <p>Focus on incremental development</p> </li> <li>Begin with minimal solutions and build up as needed</li> <li> <p>Validate each step before adding complexity</p> </li> <li> <p>Establish regular check-in points</p> </li> <li>Reconnect to original goals frequently</li> <li> <p>Verify that current direction aligns with requirements</p> </li> <li> <p>Challenge complexity</p> </li> <li>Ask for justification of complex components</li> <li> <p>Request simpler alternatives when appropriate</p> </li> <li> <p>Leverage existing tools</p> </li> <li>Start with available libraries and frameworks</li> <li>Question custom implementations of solved problems</li> </ol>"},{"location":"antipatterns/#how-to-use-these-guides","title":"How to Use These Guides","text":"<ul> <li>Reference a specific antipattern when you detect it</li> <li>Apply the suggested interventions to redirect the AI assistant</li> <li>Use the preventive measures when starting new projects</li> <li>Add your own observations and successful strategies</li> </ul>"},{"location":"antipatterns/ai-tooling-antipatterns/","title":"AI Tooling Antipatterns","text":"<p>Beyond coding practices, several antipatterns specifically relate to how humans design and use AI tools in development workflows. These patterns hamper the effectiveness of AI agents and create friction in development processes.</p>"},{"location":"antipatterns/ai-tooling-antipatterns/#tool-access-asymmetry","title":"Tool Access Asymmetry","text":"<p>Pattern: Creating tools for AI agents but making them difficult to discover or invoke, requiring humans to explicitly mention them.</p> <p>Problems: - Tools remain underutilized - Humans must remember to prompt for tool usage - Knowledge about available tools doesn't persist between sessions - Tool capabilities aren't automatically matched to problems</p> <p>Solution: Implement tool discovery mechanisms like <code>.clinerules</code> files that explicitly document available tools and when to use them.</p>"},{"location":"antipatterns/ai-tooling-antipatterns/#verbosity-amplification","title":"Verbosity Amplification","text":"<p>Pattern: Creating tools that generate excessively verbose output for AI consumption, wasting tokens on formatting, spinners, and human-readable decorations.</p> <p>Problems: - Consumes token budget with non-functional information - Reduces context available for actual problem-solving - Creates noise that can obscure important signals - Scales poorly as projects grow larger</p> <p>Solution: Implement log insulation patterns that redirect verbose output to files while providing AI agents with compact, structured summaries.</p>"},{"location":"antipatterns/ai-tooling-antipatterns/#missed-instrumentation-opportunities","title":"Missed Instrumentation Opportunities","text":"<p>Pattern: Failing to instrument projects with AI-specific hooks and sensors that could provide valuable context.</p> <p>Problems: - AI lacks awareness of implicit project patterns - Runtime behavior remains invisible to AI agents - Performance implications aren't available for decision-making - Historical usage patterns can't inform recommendations</p> <p>Solution: Add instrumentation that captures and summarizes runtime behavior, performance metrics, and usage patterns in AI-friendly formats.</p>"},{"location":"antipatterns/ai-tooling-antipatterns/#brittle-tool-chaining","title":"Brittle Tool Chaining","text":"<p>Pattern: Creating tools that work in isolation but fail when used in sequence due to incompatible formats or assumptions.</p> <p>Problems: - Requires manual intervention between tool invocations - Creates context loss when switching between tools - Prevents end-to-end automation of complex workflows - Results in redundant processing and token usage</p> <p>Solution: Design tools with consistent input/output formats and explicit support for composition and piping of results.</p>"},{"location":"antipatterns/ai-tooling-antipatterns/#configuration-proliferation","title":"Configuration Proliferation","text":"<p>Pattern: Creating numerous tool-specific configuration files instead of unified configuration approaches.</p> <p>Problems: - Increases cognitive load for both humans and AI - Creates configuration drift and inconsistencies - Makes it difficult to discover all relevant settings - Leads to redundant configuration across tools</p> <p>Solution: Implement unified configuration approaches like <code>.aiconfig</code> files that centralize settings across multiple tools and provide discovery mechanisms.</p>"},{"location":"antipatterns/ai-tooling-antipatterns/#ignoring-feedback-loops","title":"Ignoring Feedback Loops","text":"<p>Pattern: Building tools without mechanisms to capture success/failure metrics or improvement suggestions.</p> <p>Problems: - Tool effectiveness can't be measured or improved - Successful patterns aren't identified and reinforced - Problematic tools continue to be used despite issues - Evolution of tooling becomes opinion-based rather than data-driven</p> <p>Solution: Add telemetry to AI tooling that captures usage patterns, success rates, and improvement suggestions that can inform tool evolution.</p>"},{"location":"antipatterns/ai-tooling-antipatterns/#addressing-ai-tooling-antipatterns","title":"Addressing AI Tooling Antipatterns","text":"<p>To avoid these antipatterns in your AI development workflow:</p> <ol> <li>Implement Explicit Tool Documentation:</li> <li>Create <code>.clinerules</code> files at project root</li> <li>Document when and how to use each tool</li> <li> <p>Provide examples of proper usage</p> </li> <li> <p>Design for Token Efficiency:</p> </li> <li>Audit tool output for unnecessary verbosity</li> <li>Create structured, compact output formats for AI consumption</li> <li> <p>Implement log redirection for verbose processes</p> </li> <li> <p>Enable Tool Composition:</p> </li> <li>Standardize data formats between tools</li> <li>Create pipeline capabilities for multi-stage processes</li> <li> <p>Design tools to retain context across invocations</p> </li> <li> <p>Centralize Configuration:</p> </li> <li>Implement unified configuration for AI tooling</li> <li>Create discovery mechanisms for settings</li> <li> <p>Document configuration options clearly</p> </li> <li> <p>Build in Measurement:</p> </li> <li>Track tool usage and effectiveness</li> <li>Collect improvement suggestions</li> <li>Evolve tooling based on actual usage patterns</li> </ol> <p>By avoiding these antipatterns, you can create more effective AI tooling ecosystems that enhance agent productivity and integrate smoothly into development workflows.</p>"},{"location":"antipatterns/context-overwhelming/","title":"Context Overwhelming","text":"<p>When humans provide excessive information to AI coding agents, overwhelming their context window with irrelevant details. Instead of focusing the agent on the specific task, they flood it with large codebases, excessive documentation, or tangential information that reduces effectiveness.</p>"},{"location":"antipatterns/context-overwhelming/#how-to-spot-it","title":"How to Spot It","text":"<p>Look for these signs:</p> <ul> <li>Pasting entire files instead of relevant snippets</li> <li>Sharing multiple files when only one is needed for the task</li> <li>Including detailed documentation unrelated to the current issue</li> <li>Providing lengthy logs or error messages without filtering</li> <li>Filling context with repository structure explanations</li> <li>Continuously adding more context without curating previous information</li> <li>Agent responses indicating confusion about priorities or task scope</li> </ul>"},{"location":"antipatterns/context-overwhelming/#why-its-harmful","title":"Why It's Harmful","text":"<ul> <li>Wastes tokens on irrelevant information</li> <li>Forces the agent to spend time processing unnecessary context</li> <li>Pushes relevant information out of the context window</li> <li>Reduces focus on the actual problem to solve</li> <li>Creates confusion about which parts are important</li> <li>Leads to solutions addressing the wrong aspects of the problem</li> <li>Increases likelihood of context truncation during processing</li> </ul>"},{"location":"antipatterns/context-overwhelming/#what-to-do-about-it","title":"What to Do About It","text":"<p>When you see this happening:</p> <ol> <li>Say \"Let's focus only on the specific code that relates to this issue.\"</li> <li>Ask \"What's the minimal context needed for this particular task?\"</li> <li>Suggest \"Let's start fresh with just the essential information.\"</li> <li>Provide guidance: \"Focus only on the authentication flow; we can ignore the UI components for now.\"</li> </ol> <p>To prevent it next time:</p> <ol> <li>Create context compression tools that extract only relevant code</li> <li>Establish a \"minimal viable context\" principle for each task type</li> <li>Implement context curators that filter and prioritize information</li> <li>Use project-specific templates that guide context sharing</li> <li>Train team members on effective context scoping</li> </ol>"},{"location":"antipatterns/context-overwhelming/#example","title":"Example","text":"<p>Human: \"Here's our entire codebase with 50 files. I need you to fix a bug in the login form validation.\"</p> <p>You: \"Let's focus specifically on the login form component and the validation logic. Could you share just those files rather than the entire codebase? This will help us address the issue more effectively.\"</p>"},{"location":"antipatterns/context-overwhelming/#benefits-of-fixing-this","title":"Benefits of Fixing This","text":"<ul> <li>More focused and accurate solutions</li> <li>Faster response times</li> <li>Better use of token allocations</li> <li>Clearer understanding of the actual problem</li> <li>Increased agent productivity</li> <li>Less context getting pushed out of the window</li> <li>More memory available for complex reasoning</li> </ul>"},{"location":"antipatterns/dependency-blindness/","title":"Dependency Blindness","text":"<p>When AI agents operate without awareness of the project's dependencies, versions, or package ecosystem. The agent proposes solutions that use unavailable dependencies, incompatible versions, or overlooked package limitations, leading to implementation errors and integration challenges.</p>"},{"location":"antipatterns/dependency-blindness/#how-to-spot-it","title":"How to Spot It","text":"<p>Look for these signs:</p> <ul> <li>Suggesting libraries not listed in package.json/requirements.txt</li> <li>Recommending features from newer versions than those in use</li> <li>Ignoring compatibility constraints between dependencies</li> <li>Overlooking transitive dependency issues</li> <li>Missing peer dependency requirements</li> <li>Creating import statements for packages not installed</li> <li>Ignoring platform-specific dependency limitations</li> </ul>"},{"location":"antipatterns/dependency-blindness/#why-its-harmful","title":"Why It's Harmful","text":"<ul> <li>Creates solutions that can't be implemented as written</li> <li>Introduces version conflicts that break builds</li> <li>Requires additional debugging and implementation time</li> <li>Adds unnecessary dependencies when existing ones would suffice</li> <li>Increases complexity of the dependency tree</li> <li>Potentially introduces security vulnerabilities</li> <li>Reduces confidence in AI-generated solutions</li> </ul>"},{"location":"antipatterns/dependency-blindness/#what-to-do-about-it","title":"What to Do About It","text":"<p>When you see this happening:</p> <ol> <li>Say \"Let's check which dependencies we already have in the project.\"</li> <li>Ask \"Can we implement this using our existing dependency set?\"</li> <li>Clarify: \"We're using version X.Y.Z of this library, not the latest version.\"</li> <li>Request: \"Please verify that your solution works with our current dependencies.\"</li> </ol> <p>To prevent it next time:</p> <ol> <li>Create a dependency information tool that extracts and summarizes package details</li> <li>Include package.json/requirements.txt in the initial context</li> <li>Generate \"allowed dependencies\" lists for different project areas</li> <li>Build version constraint checkers for AI-generated code</li> <li>Implement a dependency validator for preprocessing AI suggestions</li> </ol>"},{"location":"antipatterns/dependency-blindness/#example","title":"Example","text":"<p>AI: \"You should use React Query for this data fetching pattern. Here's how you could implement it...\"</p> <p>You: \"We're actually standardized on SWR for data fetching in this project. Could you revise your approach to use our existing SWR pattern instead of introducing React Query?\"</p>"},{"location":"antipatterns/dependency-blindness/#benefits-of-fixing-this","title":"Benefits of Fixing This","text":"<ul> <li>Solutions that work out-of-the-box without dependency changes</li> <li>Consistent use of libraries across the project</li> <li>Reduced integration effort</li> <li>Lower complexity and maintenance burden</li> <li>Better alignment with team standards</li> <li>Fewer security risks from unnecessary dependencies</li> <li>More predictable builds and deployments</li> </ul>"},{"location":"antipatterns/glossary-avoidance/","title":"Domain Glossary Avoidance","text":"<p>When AI agents fail to establish or use a consistent vocabulary for domain-specific terms. Instead of creating and maintaining a shared understanding of domain language, the agent introduces terminology inconsistencies, misinterprets domain concepts, or uses general terms that lack domain precision.</p>"},{"location":"antipatterns/glossary-avoidance/#how-to-spot-it","title":"How to Spot It","text":"<p>Look for these signs:</p> <ul> <li>Inconsistent naming of domain concepts across messages</li> <li>Using generic terms when domain-specific ones exist</li> <li>Misinterpretation of domain-specific terminology</li> <li>Failure to clarify ambiguous domain terms</li> <li>Creating new terms instead of using established domain language</li> <li>Avoiding explicit definition of key business concepts</li> <li>Mixing technical and domain vocabularies inappropriately</li> </ul>"},{"location":"antipatterns/glossary-avoidance/#why-its-harmful","title":"Why It's Harmful","text":"<ul> <li>Creates confusion about core domain concepts</li> <li>Produces code that doesn't reflect the business domain</li> <li>Makes communication between technical and domain experts difficult</li> <li>Results in inconsistent naming in the codebase</li> <li>Reduces the value of domain-driven approaches</li> <li>Makes requirements harder to trace to implementation</li> <li>Creates technical debt through terminology drift</li> </ul>"},{"location":"antipatterns/glossary-avoidance/#what-to-do-about-it","title":"What to Do About It","text":"<p>When you see this happening:</p> <ol> <li>Say \"Let's establish a clear glossary of domain terms for this project.\"</li> <li>Ask \"What's the correct domain term for this concept in your business?\"</li> <li>Suggest \"Can we create a reference for domain terminology that we'll use consistently?\"</li> <li>Clarify: \"When you say X, does that correspond to concept Y in the domain model?\"</li> </ol> <p>To prevent it next time:</p> <ol> <li>Create domain glossary extraction tools that identify key terms</li> <li>Build terminology consistency checkers for conversations</li> <li>Implement domain term highlighting in documentation</li> <li>Develop domain-specific language validators for code</li> <li>Maintain persistent domain glossaries across sessions</li> </ol>"},{"location":"antipatterns/glossary-avoidance/#example","title":"Example","text":"<p>Human: \"We need to implement the customer journey tracking.\"</p> <p>AI: \"I'll create a user flow tracking system with the following components...\"</p> <p>You: \"Let's clarify our domain language first. In our business, we specifically use 'customer journey' to refer to the stages a customer goes through, from 'prospect' to 'lead' to 'opportunity' to 'client'. Could you revise your approach to use our established domain terminology?\"</p>"},{"location":"antipatterns/glossary-avoidance/#benefits-of-fixing-this","title":"Benefits of Fixing This","text":"<ul> <li>Creates code that accurately reflects the business domain</li> <li>Improves communication between technical and domain experts</li> <li>Ensures consistent use of terminology across the codebase</li> <li>Makes domain concepts explicit in the implementation</li> <li>Facilitates better requirements tracing</li> <li>Reduces confusion and misinterpretation</li> <li>Supports effective domain-driven design</li> </ul>"},{"location":"antipatterns/historical-amnesia/","title":"Historical Amnesia","text":"<p>When AI agents forget critical context from earlier in the conversation when generating solutions. Despite previous discussions about requirements, constraints, or architectural decisions, the agent produces code that ignores or contradicts this established context, requiring repeated correction.</p>"},{"location":"antipatterns/historical-amnesia/#how-to-spot-it","title":"How to Spot It","text":"<p>Look for these signs:</p> <ul> <li>Reverting to approaches that were explicitly ruled out earlier</li> <li>Forgetting established requirements from previous messages</li> <li>Contradicting design decisions made earlier in the conversation</li> <li>Ignoring established naming conventions discussed previously</li> <li>Reintroducing patterns that were determined to be problematic</li> <li>Asking for information that was already provided</li> <li>Acting as if seeing the problem for the first time</li> </ul>"},{"location":"antipatterns/historical-amnesia/#why-its-harmful","title":"Why It's Harmful","text":"<ul> <li>Wastes time repeating information and requirements</li> <li>Creates inconsistent solutions that don't build on previous work</li> <li>Requires constant vigilance and correction</li> <li>Reduces the value of extended conversations</li> <li>Makes iterative development difficult</li> <li>Results in solutions that ignore important constraints</li> <li>Erodes trust in the agent's ability to maintain context</li> </ul>"},{"location":"antipatterns/historical-amnesia/#what-to-do-about-it","title":"What to Do About It","text":"<p>When you see this happening:</p> <ol> <li>Say \"Let's recall that we decided X earlier in our conversation.\"</li> <li>Create summaries: \"To recap our decisions so far: we're using approach A, avoiding pattern B, and focusing on requirement C.\"</li> <li>Reference previous messages: \"As we discussed in message #3, we need to maintain backward compatibility.\"</li> <li>Ask: \"Can you ensure this solution incorporates our previous decisions about X, Y, and Z?\"</li> </ol> <p>To prevent it next time:</p> <ol> <li>Implement conversation summarizers that extract key decisions</li> <li>Create project decision registers that persist across sessions</li> <li>Add explicit decision tracking in conversation</li> <li>Develop tools that extract requirements from conversation history</li> <li>Tag important context with \"remember this\" markers</li> </ol>"},{"location":"antipatterns/historical-amnesia/#example","title":"Example","text":"<p>Human: \"As we discussed earlier, we need to implement this using functional components and hooks.\"</p> <p>AI: \"Here's a class component implementation of the feature...\"</p> <p>You: \"Let's stick with our previous decision to use functional components and hooks for this implementation, as we discussed. Could you revise your solution to align with that approach?\"</p>"},{"location":"antipatterns/historical-amnesia/#benefits-of-fixing-this","title":"Benefits of Fixing This","text":"<ul> <li>Maintains coherent development progress across the conversation</li> <li>Reduces repetition and correction</li> <li>Creates more cohesive, requirement-aligned solutions</li> <li>Enables successful iterative development</li> <li>Builds trust in the agent's ability to maintain context</li> <li>Allows focus on new challenges rather than revisiting old decisions</li> <li>Creates more efficient development conversations</li> </ul>"},{"location":"antipatterns/implementation-tunneling/","title":"Implementation Tunneling","text":"<p>When AI agents persist with a single implementation approach despite evidence it's flawed or suboptimal. Instead of recognizing when an approach isn't working and pivoting to alternatives, the agent repeatedly attempts to fix the same approach with minor variations, creating a tunnel-vision effect.</p>"},{"location":"antipatterns/implementation-tunneling/#how-to-spot-it","title":"How to Spot It","text":"<p>Look for these signs:</p> <ul> <li>Repeatedly adjusting the same solution after multiple failures</li> <li>Ignoring fundamental flaws in the chosen approach</li> <li>Making increasingly complex modifications to force an approach to work</li> <li>Dismissing alternative approaches without proper evaluation</li> <li>Sticking with familiar patterns even when inappropriate</li> <li>Adding workarounds instead of reconsidering core approach</li> <li>Unwillingness to start fresh with a different strategy</li> </ul>"},{"location":"antipatterns/implementation-tunneling/#why-its-harmful","title":"Why It's Harmful","text":"<ul> <li>Wastes time on approaches unlikely to succeed</li> <li>Creates unnecessarily complex or brittle solutions</li> <li>Misses opportunities for simpler, more elegant approaches</li> <li>Produces code with excessive workarounds</li> <li>Leads to premature optimization of flawed approaches</li> <li>Results in solutions that are difficult to maintain</li> <li>Demonstrates poor problem-solving adaptability</li> </ul>"},{"location":"antipatterns/implementation-tunneling/#what-to-do-about-it","title":"What to Do About It","text":"<p>When you see this happening:</p> <ol> <li>Say \"I think we may be going down a rabbit hole with this approach.\"</li> <li>Suggest \"Let's take a step back and reconsider alternative strategies.\"</li> <li>Ask \"What other approaches could we try instead of continuing to modify this one?\"</li> <li>Propose \"Let's start with a simpler solution and see if it avoids these issues altogether.\"</li> </ol> <p>To prevent it next time:</p> <ol> <li>Implement approach diversity tools that suggest multiple solutions</li> <li>Set iteration limits before requiring a strategy reassessment</li> <li>Create \"clean slate\" protocols after multiple failed iterations</li> <li>Build alternative approach generators for common problems</li> <li>Establish complexity warning systems that flag over-engineered solutions</li> </ol>"},{"location":"antipatterns/implementation-tunneling/#example","title":"Example","text":"<p>AI: \"Let's add another nested condition to handle this edge case... and then we'll need a special flag to track the state between these operations...\"</p> <p>You: \"It seems like we're adding a lot of complexity to make this approach work. Let's take a step back\u2014could we solve this more cleanly with a different pattern altogether? Perhaps a state machine or an event-driven approach would be more suitable?\"</p>"},{"location":"antipatterns/implementation-tunneling/#benefits-of-fixing-this","title":"Benefits of Fixing This","text":"<ul> <li>Discovers more optimal solutions earlier</li> <li>Avoids excessive complexity and technical debt</li> <li>Creates more maintainable and understandable code</li> <li>Demonstrates more flexible problem-solving</li> <li>Saves development time by abandoning poor approaches quickly</li> <li>Encourages consideration of multiple strategies</li> <li>Produces more elegant, efficient solutions</li> </ul>"},{"location":"antipatterns/inconsistent-conventions/","title":"Inconsistent Conventions","text":"<p>When AI agents ignore or deviate from established project conventions and style guidelines. Instead of maintaining consistent patterns across the codebase, the agent introduces its own naming, formatting, or architectural approaches, creating inconsistency that reduces maintainability.</p>"},{"location":"antipatterns/inconsistent-conventions/#how-to-spot-it","title":"How to Spot It","text":"<p>Look for these signs:</p> <ul> <li>Different naming conventions than the rest of the codebase (camelCase vs snake_case)</li> <li>Inconsistent file organization or module structure</li> <li>Deviation from established architectural patterns</li> <li>Using different comment styles or documentation formats</li> <li>Applying different error handling approaches</li> <li>Implementing different testing patterns</li> <li>Structuring functions or methods differently</li> <li>Mixing code styles within a single file</li> </ul>"},{"location":"antipatterns/inconsistent-conventions/#why-its-harmful","title":"Why It's Harmful","text":"<ul> <li>Creates a patchwork codebase with inconsistent styles</li> <li>Makes code harder to read and understand</li> <li>Increases cognitive load for developers</li> <li>Complicates maintenance and refactoring</li> <li>Makes automated tooling less effective</li> <li>Creates confusion about project standards</li> <li>Requires manual clean-up and standardization</li> </ul>"},{"location":"antipatterns/inconsistent-conventions/#what-to-do-about-it","title":"What to Do About It","text":"<p>When you see this happening:</p> <ol> <li>Say \"This doesn't match our project's conventions. Let's revise to be consistent.\"</li> <li>Point out specific examples: \"We use PascalCase for component names, not kebab-case.\"</li> <li>Provide reference: \"Here's how error handling is done in the rest of the codebase.\"</li> <li>Ask: \"Can you update this to match our established patterns?\"</li> </ol> <p>To prevent it next time:</p> <ol> <li>Create style guide extractors that analyze existing code patterns</li> <li>Implement convention enforcers that validate generated code</li> <li>Provide explicit examples of project conventions in prompts</li> <li>Add linting tools that automatically flag convention deviations</li> <li>Generate project-specific templates for common patterns</li> </ol>"},{"location":"antipatterns/inconsistent-conventions/#example","title":"Example","text":"<p>AI: \"Here's a new React component using hooks and arrow functions...\"</p> <p>You: \"I notice you've used hooks and arrow functions, but our codebase consistently uses class components and regular function declarations. Could you revise your solution to match our established patterns?\"</p>"},{"location":"antipatterns/inconsistent-conventions/#benefits-of-fixing-this","title":"Benefits of Fixing This","text":"<ul> <li>Maintains a cohesive, consistent codebase</li> <li>Reduces cognitive load when reading and maintaining code</li> <li>Makes code reviews faster and more focused on logic, not style</li> <li>Enables more effective use of automated tools</li> <li>Ensures generated code integrates seamlessly</li> <li>Preserves architectural consistency</li> <li>Makes knowledge transfer easier for team members</li> </ul>"},{"location":"antipatterns/library-reinvention/","title":"Library and Framework Reinvention","text":"<p>When AI assistants implement custom solutions for problems that already have established, well-tested libraries or frameworks. Instead of leveraging existing tools, they create novel implementations that duplicate available functionality, causing unnecessary complexity and potential reliability issues.</p>"},{"location":"antipatterns/library-reinvention/#how-to-spot-it","title":"How to Spot It","text":"<p>Look for these signs:</p> <ul> <li>Lengthy custom implementations of common functionality (authentication, validation, etc.)</li> <li>Phrases like \"let's create our own X\" without justifying why existing solutions are inadequate</li> <li>Absence of import statements for standard libraries that would solve the problem</li> <li>Complex utility functions that replicate standard library features</li> <li>Implementing low-level functionality (HTTP clients, JSON parsing, etc.) from scratch</li> <li>Detailed explanations of algorithms that exist in standard libraries</li> <li>No mention of established packages when proposing solutions in domains with clear standards</li> </ul>"},{"location":"antipatterns/library-reinvention/#why-its-harmful","title":"Why It's Harmful","text":"<ul> <li>Creates maintenance burden for custom code</li> <li>Misses security features and edge case handling present in established libraries</li> <li>Wastes time reinventing solutions to already-solved problems</li> <li>Extends development time</li> <li>Produces inconsistent behavior compared to standard implementations</li> <li>Generates technical debt from non-standard approaches</li> </ul>"},{"location":"antipatterns/library-reinvention/#what-to-do-about-it","title":"What to Do About It","text":"<p>When you see this happening:</p> <ol> <li>Ask \"Is there an existing library or framework that handles this for us?\"</li> <li>Request \"What established libraries could we use instead of building this ourselves?\"</li> <li>Question \"What are the tradeoffs between your custom implementation and using library X?\"</li> <li>Challenge \"Why are we building this from scratch rather than using existing tools?\"</li> </ol> <p>To prevent it next time:</p> <ol> <li>Start with discovery: \"What libraries are commonly used for this type of problem?\"</li> <li>Set expectations: \"Our default approach is to use existing libraries unless there's a compelling reason not to.\"</li> <li>Request library-first solutions: \"Please suggest solutions that leverage established libraries first.\"</li> <li>Define boundaries: \"We only want custom implementations for X, Y, and Z; everything else should use standard libraries.\"</li> <li>Require justification: \"If suggesting a custom implementation, explain why existing libraries don't meet our needs.\"</li> </ol>"},{"location":"antipatterns/library-reinvention/#example","title":"Example","text":"<p>AI: \"For handling HTTP requests, we'll create a custom HttpClient class that manages connections and handles different content types. Here's the implementation...\"</p> <p>You: \"Let's use Axios (or fetch in a browser environment) instead of writing our own HTTP client. Can you revise the approach to leverage that established library?\"</p>"},{"location":"antipatterns/library-reinvention/#benefits-of-fixing-this","title":"Benefits of Fixing This","text":"<ul> <li>Reduces development time and effort</li> <li>Creates more reliable and secure solutions</li> <li>Makes onboarding easier for developers familiar with standard libraries</li> <li>Improves maintainability and upgradability</li> <li>Provides access to community support and documentation</li> <li>Focuses effort on novel aspects of the problem rather than solved ones</li> </ul>"},{"location":"antipatterns/premature-architecture/","title":"Premature Architecture Complexity","text":"<p>When AI assistants create overly complex architectures before fully understanding requirements. They generate impressive-looking full-stack solutions with numerous components, layers, and abstractions that are unnecessary for the actual problem.</p>"},{"location":"antipatterns/premature-architecture/#how-to-spot-it","title":"How to Spot It","text":"<p>Look for these signs:</p> <ul> <li>Complex architecture diagrams or explanations appear before requirements are fully discussed</li> <li>Introduction of multiple layers of abstraction in initial proposals</li> <li>Inclusion of components to handle edge cases that haven't been specified</li> <li>Proposing integration with numerous external systems without clear justification</li> <li>Long explanations of architectural patterns without tying them to specific requirements</li> <li>Using phrases like \"we'll need X, Y, and Z to make this scalable\" before knowing the scale</li> </ul>"},{"location":"antipatterns/premature-architecture/#why-its-harmful","title":"Why It's Harmful","text":"<ul> <li>Wastes time implementing unnecessary features</li> <li>Creates maintenance burden for unused components</li> <li>Makes changes difficult as requirements evolve</li> <li>Obscures core functionality behind abstraction layers</li> <li>Extends development time without adding value</li> </ul>"},{"location":"antipatterns/premature-architecture/#what-to-do-about-it","title":"What to Do About It","text":"<p>When you see this happening:</p> <ol> <li>Say \"Let's pause on the architecture and focus on understanding the core problem first.\"</li> <li>Ask \"Can you provide a minimal version that addresses just these specific requirements?\"</li> <li>Request \"For each component you're proposing, explain what specific requirement it addresses.\"</li> </ol> <p>To prevent it next time:</p> <ol> <li>Set boundaries: \"We need a solution that uses at most X components and can be implemented in Y time.\"</li> <li>Be explicit: \"The priority is solving A, B, and C; everything else is optional.\"</li> <li>Start small: \"Let's build the simplest version first, then iterate.\"</li> <li>Define success: \"Here's how we'll know if the solution is working...\"</li> <li>Apply YAGNI: Remind the AI that \"You Aren't Gonna Need It\" for premature features</li> </ol>"},{"location":"antipatterns/premature-architecture/#example","title":"Example","text":"<p>AI: \"For this contact form, we'll need a React frontend with Redux for state management, a Node.js backend with Express, a MongoDB database, a Redis cache for session management, and we should set up a message queue with RabbitMQ to handle...\"</p> <p>You: \"Let's take a step back. We just need a simple contact form that emails submissions to an address. Can you propose the simplest solution that meets just that need?\"</p>"},{"location":"antipatterns/premature-architecture/#benefits-of-fixing-this","title":"Benefits of Fixing This","text":"<ul> <li>Faster development focused on delivering actual value</li> <li>More maintainable code</li> <li>Better alignment between requirements and implementation</li> <li>Greater flexibility for future changes</li> <li>Reduced complexity for developers</li> </ul>"},{"location":"antipatterns/purpose-drift/","title":"Purpose Drift During Refactoring","text":"<p>When AI assistants lose sight of the original purpose during refactoring. The code undergoes continuous improvements, but these changes gradually disconnect from the original objectives, resulting in a solution that might be \"cleaner\" but no longer addresses the core problem effectively.</p>"},{"location":"antipatterns/purpose-drift/#how-to-spot-it","title":"How to Spot It","text":"<p>Look for these signs:</p> <ul> <li>Multiple successive refactoring suggestions without reconnecting to original goals</li> <li>Increasing complexity without corresponding functional improvements</li> <li>Comments like \"we can improve this further by...\" without justifying the improvements</li> <li>Disappearance of key functionality during \"simplification\"</li> <li>Extended discussions about implementation details with no reference to user needs</li> <li>Inability to explain how a change relates to the original requirements</li> <li>Significant changes to public interfaces without clear benefit</li> </ul>"},{"location":"antipatterns/purpose-drift/#why-its-harmful","title":"Why It's Harmful","text":"<ul> <li>Causes loss of essential functionality</li> <li>Wastes development effort</li> <li>Creates code that's technically \"better\" but functionally worse</li> <li>Extends development time without adding value</li> <li>Produces solutions that drift from user needs</li> <li>Makes it difficult to explain the purpose of code sections</li> </ul>"},{"location":"antipatterns/purpose-drift/#what-to-do-about-it","title":"What to Do About It","text":"<p>When you see this happening:</p> <ol> <li>Say \"Let's step back and remember what problem we're trying to solve.\"</li> <li>Ask \"The original goal was X. How does this refactoring help with that?\"</li> <li>Question: \"What specific improvement will users or developers see from this change?\"</li> <li>Set limits: \"Let's limit our refactoring to areas that directly impact our current goals.\"</li> </ol> <p>To prevent it next time:</p> <ol> <li>Document purpose clearly and revisit it regularly</li> <li>Define specific goals: \"We're refactoring to achieve X, Y, and Z improvements.\"</li> <li>Add checkpoints: After each refactoring step, verify the solution still meets requirements</li> <li>Make connections: For each refactoring, connect it to a specific requirement or pain point</li> <li>Set time limits: \"We'll spend at most X time on refactoring before moving on.\"</li> <li>Apply the \"rule of three\": Wait until you see the same problem three times before refactoring</li> </ol>"},{"location":"antipatterns/purpose-drift/#example","title":"Example","text":"<p>AI: \"Now that we've refactored the data access layer, we should also rework the service layer to use dependency injection, and then update the controller to follow CQRS principles...\"</p> <p>You: \"Before we continue refactoring, let's check if we've maintained the original functionality. The main goal was to fix the bug where users couldn't update their profiles. Does our current solution address that, and is further refactoring necessary for that specific goal?\"</p>"},{"location":"antipatterns/purpose-drift/#benefits-of-fixing-this","title":"Benefits of Fixing This","text":"<ul> <li>Maintains focus on delivering actual value</li> <li>Reduces wasted effort on unnecessary improvements</li> <li>Aligns technical decisions with business outcomes</li> <li>Creates clearer justification for refactoring efforts</li> <li>Makes development progress more predictable</li> <li>Simplifies communication about the purpose of code changes</li> </ul>"},{"location":"antipatterns/separation-of-concerns/","title":"Failure to Separate Concerns","text":"<p>When AI assistants create code that mixes different responsibilities within the same components. Rather than organizing code around clear boundaries of responsibility, the implementation intermingles concerns like business logic, data access, presentation, and error handling, creating tight coupling and dependencies.</p>"},{"location":"antipatterns/separation-of-concerns/#how-to-spot-it","title":"How to Spot It","text":"<p>Look for these signs:</p> <ul> <li>Methods or classes that serve multiple distinct purposes</li> <li>Direct database calls within UI components or business logic</li> <li>Formatting and presentation logic mixed with data processing</li> <li>Error handling scattered throughout the codebase</li> <li>Configuration and environment concerns embedded in business logic</li> <li>Large, complex functions that handle multiple aspects of a process</li> <li>Difficulty explaining what a component's single responsibility is</li> <li>Cross-cutting concerns (logging, authorization) duplicated everywhere</li> </ul>"},{"location":"antipatterns/separation-of-concerns/#why-its-harmful","title":"Why It's Harmful","text":"<ul> <li>Makes maintaining or extending the codebase difficult</li> <li>Increases bugs when changing one aspect affects others</li> <li>Creates testing challenges due to inability to isolate components</li> <li>Reduces code reusability</li> <li>Makes onboarding new developers harder</li> <li>Creates tight coupling that makes changes risky</li> <li>Limits ability to refactor or replace individual components</li> </ul>"},{"location":"antipatterns/separation-of-concerns/#what-to-do-about-it","title":"What to Do About It","text":"<p>When you see this happening:</p> <ol> <li>Ask \"What is the single responsibility of this component?\"</li> <li>Point out \"I notice this class is handling both X and Y. Should we separate these?\"</li> <li>Suggest \"Can we separate the data access from the business logic here?\"</li> <li>Question \"What are the natural boundaries between different concerns in this system?\"</li> </ol> <p>To prevent it next time:</p> <ol> <li>Start with modeling: \"Before coding, let's identify the key abstractions and responsibilities.\"</li> <li>Set architectural patterns: \"We'll follow clean architecture with these specific layers...\"</li> <li>Define interfaces first: \"Let's define the interfaces between components before implementation.\"</li> <li>Apply SOLID principles: \"Each class should have only one reason to change.\"</li> <li>Visualize architecture: Sketch out the separation of concerns before implementation</li> <li>Separate cross-cutting concerns: \"Authentication, logging, etc., should be handled through dedicated mechanisms.\"</li> </ol>"},{"location":"antipatterns/separation-of-concerns/#example","title":"Example","text":"<p>AI: \"Here's the UserController class that handles authentication, retrieves user data from the database, formats it for the UI, and logs all activities...\"</p> <p>You: \"This controller is doing too many things. Let's separate these concerns: authentication should be middleware, data access should be in a repository, formatting in a separate view model or service, and logging through a cross-cutting concern. Can you refactor with these separations?\"</p>"},{"location":"antipatterns/separation-of-concerns/#benefits-of-fixing-this","title":"Benefits of Fixing This","text":"<ul> <li>Creates more maintainable and understandable code</li> <li>Makes testing easier through properly isolated components</li> <li>Allows changing individual parts without affecting others</li> <li>Improves reusability of components</li> <li>Gives a clearer mental model of the system</li> <li>Reduces risk when making changes</li> <li>Creates more natural division of work among team members</li> </ul>"},{"location":"antipatterns/separation-of-concerns/#quick-reference-clean-separation","title":"Quick Reference: Clean Separation","text":"<ol> <li>Presentation Layer: UI components, controllers, view models</li> <li>Application Layer: Use cases, application services, coordination</li> <li>Domain Layer: Business logic, entities, domain services</li> <li>Infrastructure Layer: Data access, external services, technical implementation</li> </ol>"},{"location":"antipatterns/separation-of-concerns/#warning-signs","title":"Warning Signs","text":"<ul> <li>Methods longer than a screen</li> <li>Classes with more than one reason to change</li> <li>Difficulty writing unit tests</li> <li>\"God objects\" that know too much</li> <li>Direct database queries in UI handlers</li> <li>Business logic in presentation components</li> </ul>"},{"location":"antipatterns/solutionism/","title":"Solutionism Over Problem Analysis","text":"<p>When AI agents rush to propose solutions before thoroughly understanding the underlying problem. Instead of analyzing requirements, constraints, and existing code, the agent jumps straight to implementing a solution, often solving the wrong problem or missing critical context.</p>"},{"location":"antipatterns/solutionism/#how-to-spot-it","title":"How to Spot It","text":"<p>Look for these signs:</p> <ul> <li>Proposing implementations without asking clarifying questions</li> <li>Minimal time spent examining existing code or architecture</li> <li>Solutions that miss key edge cases mentioned in requirements</li> <li>Lack of exploration of alternative approaches</li> <li>Skipping problem definition or requirement validation</li> <li>Diving into implementation details immediately</li> <li>No explicit analysis of trade-offs or constraints</li> </ul>"},{"location":"antipatterns/solutionism/#why-its-harmful","title":"Why It's Harmful","text":"<ul> <li>Creates solutions that solve the wrong problem</li> <li>Misses underlying issues that need addressing</li> <li>Wastes effort on implementations that need extensive rework</li> <li>Overlooks important constraints or requirements</li> <li>Results in code that doesn't integrate well with existing systems</li> <li>Produces naive solutions that don't account for edge cases</li> <li>Bypasses opportunities for simpler approaches</li> </ul>"},{"location":"antipatterns/solutionism/#what-to-do-about-it","title":"What to Do About It","text":"<p>When you see this happening:</p> <ol> <li>Pause and say \"Before we implement, let's make sure we understand the problem fully.\"</li> <li>Ask \"What are the core requirements and constraints we need to address?\"</li> <li>Suggest \"Let's analyze the existing code first to understand how this fits in.\"</li> <li>Prompt \"What are some alternative approaches we could consider?\"</li> </ol> <p>To prevent it next time:</p> <ol> <li>Create requirement analysis templates to guide initial exploration</li> <li>Implement problem statement formulation as a first step</li> <li>Build constraints discovery tools that identify system limitations</li> <li>Establish explicit design-before-implementation protocols</li> <li>Develop solution evaluation criteria before coding begins</li> </ol>"},{"location":"antipatterns/solutionism/#example","title":"Example","text":"<p>Human: \"We need to implement user profile updates.\"</p> <p>AI: \"Here's a complete React component for user profile updates with form validation...\"</p> <p>You: \"Let's take a step back. Before implementing, could you help me identify the key requirements for user profile updates? What data needs to be editable, what validation rules apply, and how does this integrate with our existing authentication system?\"</p>"},{"location":"antipatterns/solutionism/#benefits-of-fixing-this","title":"Benefits of Fixing This","text":"<ul> <li>Solutions that actually solve the right problem</li> <li>More robust implementations that handle edge cases</li> <li>Better integration with existing systems</li> <li>Potentially simpler approaches that save development time</li> <li>Increased likelihood of meeting actual user needs</li> <li>More maintainable code with clearer purpose</li> <li>Reduced rework and post-implementation fixes</li> </ul>"},{"location":"antipatterns/test-driven-design/","title":"Test-Driven Design Misapplication","text":"<p>When AI assistants blindly follow existing test patterns as a blueprint for implementation, rather than approaching the problem from first principles. Instead of using tests to verify a thoughtfully designed solution, the implementation becomes constrained by test structure.</p>"},{"location":"antipatterns/test-driven-design/#how-to-spot-it","title":"How to Spot It","text":"<p>Look for these signs:</p> <ul> <li>Implementation that mirrors test structure rather than domain concepts</li> <li>Focusing on passing tests rather than solving the underlying problem</li> <li>Function signatures designed around test mocking rather than usability</li> <li>Excessive code complexity to accommodate test patterns</li> <li>Declarations like \"based on the test, we need to implement it this way\"</li> <li>Heavy emphasis on testing terminology before solution concepts</li> </ul>"},{"location":"antipatterns/test-driven-design/#why-its-harmful","title":"Why It's Harmful","text":"<ul> <li>Creates solutions that satisfy tests but miss the actual problem</li> <li>Produces rigid designs that are difficult to evolve</li> <li>Ties implementation to testing frameworks rather than domain concepts</li> <li>Results in overengineered code just to accommodate testing</li> <li>Loses connection to the original problem statement</li> </ul>"},{"location":"antipatterns/test-driven-design/#what-to-do-about-it","title":"What to Do About It","text":"<p>When you see this happening:</p> <ol> <li>Say \"Let's set aside the tests for a moment and think about how we'd solve this problem naturally.\"</li> <li>Ask \"Why are we structuring the code this way? Is it just to match the tests?\"</li> <li>Refocus: \"What was the original problem we're trying to solve here?\"</li> <li>Suggest: \"If we were designing this from scratch without considering the tests, what would be the clearest approach?\"</li> </ol> <p>To prevent it next time:</p> <ol> <li>Start with the domain: \"Let's model the domain first, then figure out how to test it.\"</li> <li>Separate concerns: \"First we'll design the solution, then we'll figure out how to test it.\"</li> <li>Focus on fundamentals: \"What are the core concepts and operations in this domain?\"</li> <li>Clarify purpose: \"Tests should verify our solution works, not dictate its structure.\"</li> <li>Think from user perspective: \"Let's design this from the user's perspective first.\"</li> </ol>"},{"location":"antipatterns/test-driven-design/#example","title":"Example","text":"<p>AI: \"Based on the test case TestUserRegistration, we need to create a UserRegistrationManager class with these specific methods to make the tests pass...\"</p> <p>You: \"Let's take a step back and think about user registration from first principles. What's the core flow we need to implement? After we understand that, we can figure out how to structure it in a way that's both testable and maintainable.\"</p>"},{"location":"antipatterns/test-driven-design/#benefits-of-fixing-this","title":"Benefits of Fixing This","text":"<ul> <li>Creates designs that better reflect domain concepts</li> <li>Produces more flexible and adaptable code</li> <li>Establishes clearer separation between testing and implementation</li> <li>Focuses on solving problems rather than satisfying tests</li> <li>Makes refactoring easier without breaking tests</li> <li>Creates tests that verify behavior rather than implementation details</li> </ul>"},{"location":"antipatterns/velocity-imbalance/","title":"Velocity Imbalance","text":"<p>When AI agents generate code at a pace that far exceeds the team's capacity to review, test, and integrate it. This creates a bottleneck where the volume of AI-generated code overwhelms the human-driven processes meant to ensure quality, leading to reduced scrutiny, integration delays, or bypassed review processes.</p>"},{"location":"antipatterns/velocity-imbalance/#how-to-spot-it","title":"How to Spot It","text":"<p>Look for these signs:</p> <ul> <li>Large backlogs of AI-generated code awaiting review</li> <li>Decreasing thoroughness of code reviews as volume increases</li> <li>Extending deadlines due to integration bottlenecks</li> <li>Team members expressing frustration with review workload</li> <li>Increasing time between code generation and deployment</li> <li>Pressure to approve changes without adequate review</li> <li>Rise in post-integration issues and bug reports</li> </ul>"},{"location":"antipatterns/velocity-imbalance/#why-its-harmful","title":"Why It's Harmful","text":"<ul> <li>Quality suffers when reviews become cursory</li> <li>Creates pressure to rush or skip proper validation</li> <li>May lead to integration of untested or under-reviewed code</li> <li>Demoralizes team members with overwhelming review queues</li> <li>Makes tracking the state of the project difficult</li> <li>Disrupts planning and velocity predictions</li> <li>May lead to rushed deployments or feature releases</li> </ul>"},{"location":"antipatterns/velocity-imbalance/#what-to-do-about-it","title":"What to Do About It","text":"<p>When you see this happening:</p> <ol> <li>Say \"Let's slow down and ensure we can properly review what we've created.\"</li> <li>Suggest \"Instead of generating more code, let's focus on integrating what we have.\"</li> <li>Ask \"What's our current review capacity and how should we pace our development?\"</li> <li>Establish \"Let's create smaller, focused changes that are easier to review.\"</li> </ol> <p>To prevent it next time:</p> <ol> <li>Implement \"velocity governor\" tools that match AI output to team capacity</li> <li>Create review complexity estimators to better distribute review workload</li> <li>Develop progressive enhancement patterns for features</li> <li>Establish clear priorities for which components to develop first</li> <li>Build batch size limiters that restrict the amount of pending changes</li> </ol>"},{"location":"antipatterns/velocity-imbalance/#example","title":"Example","text":"<p>Human: \"Can you implement these five new features for our application?\"</p> <p>AI: \"Rather than implementing all five features at once, which would create a large review burden, let's prioritize them and tackle them sequentially. Which feature would provide the most value to start with? We can implement that one with thorough testing and documentation, get it through review and integration, and then proceed to the next one.\"</p>"},{"location":"antipatterns/velocity-imbalance/#benefits-of-fixing-this","title":"Benefits of Fixing This","text":"<ul> <li>Better quality through thorough reviews</li> <li>More sustainable development pace</li> <li>Improved team morale and reduced burnout</li> <li>Clearer project status and progress tracking</li> <li>Better alignment between generation and integration </li> <li>More predictable feature delivery</li> <li>Reduced risk of quality issues in production</li> </ul>"},{"location":"antipatterns/velocity-imbalance/#implementing-velocity-management","title":"Implementing Velocity Management","text":""},{"location":"antipatterns/velocity-imbalance/#production-capacity-analysis","title":"Production Capacity Analysis","text":"<p>Create a tool to analyze the team's review and integration capacity:</p> <pre><code>#!/bin/bash\n# analyze-velocity.sh\n\n# Analyze recent PR review velocity\nrecent_days=30\navg_review_time=$(gh pr list --state closed --limit 100 --json closedAt,createdAt \\\n  | jq -r 'map((.closedAt | fromdateiso8601) - (.createdAt | fromdateiso8601)) | add/length/86400' \\\n  | awk '{printf \"%.1f\", $1}')\n\navg_pr_size=$(git log --since=\"${recent_days} days ago\" --numstat \\\n  | awk '/^[0-9]+\\s+[0-9]+\\s+/ {plus+=$1; minus+=$2} END {print plus+minus}' \\\n  | awk -v count=\"$(git log --since=\"${recent_days} days ago\" --format=\"%H\" | wc -l)\" '{printf \"%.0f\", $1/count}')\n\ndaily_throughput=$(git log --since=\"${recent_days} days ago\" --numstat \\\n  | awk '/^[0-9]+\\s+[0-9]+\\s+/ {plus+=$1; minus+=$2} END {print plus+minus}' \\\n  | awk -v days=\"$recent_days\" '{printf \"%.0f\", $1/days}')\n\necho \"Team Velocity Analysis:\"\necho \"=======================\"\necho \"Average review time: ${avg_review_time} days\"\necho \"Average commit size: ${avg_pr_size} lines\"\necho \"Daily code throughput: ${daily_throughput} lines\"\necho \"\"\necho \"Recommendations:\"\necho \"---------------\"\necho \"Maximum new PR size: $((avg_pr_size * 2)) lines\"\necho \"Maximum WIP code: $((daily_throughput * 3)) lines\"\necho \"Target PR count: $((daily_throughput / avg_pr_size * avg_review_time)) PRs\"\n</code></pre>"},{"location":"antipatterns/velocity-imbalance/#ai-output-governor","title":"AI Output Governor","text":"<p>Create a mechanism to limit AI output based on team capacity:</p> <pre><code>// velocity-governor.ts\nexport class VelocityGovernor {\n  private pendingReviewLines: number = 0;\n  private readonly capacityConfig: CapacityConfig;\n\n  constructor(configPath: string) {\n    this.capacityConfig = this.loadConfig(configPath);\n    this.syncWithCurrentState();\n  }\n\n  canGenerateMore(estimatedLines: number): boolean {\n    return (this.pendingReviewLines + estimatedLines) &lt;= this.capacityConfig.maxPendingLines;\n  }\n\n  registerGeneratedCode(filePath: string, lineCount: number): void {\n    this.pendingReviewLines += lineCount;\n    this.persistState();\n  }\n\n  registerCompletedReview(filePath: string): void {\n    // Get the line count of the file\n    const lineCount = this.getFileLineCount(filePath);\n    this.pendingReviewLines -= lineCount;\n    this.persistState();\n  }\n\n  getCurrentUtilization(): UtilizationStats {\n    return {\n      pendingLines: this.pendingReviewLines,\n      capacityLimit: this.capacityConfig.maxPendingLines,\n      utilizationPercentage: (this.pendingReviewLines / this.capacityConfig.maxPendingLines) * 100,\n      estimatedClearTime: this.pendingReviewLines / this.capacityConfig.dailyThroughput\n    };\n  }\n\n  private syncWithCurrentState(): void {\n    // Calculate pending lines from current PRs\n    this.pendingReviewLines = this.calculatePendingReviewLines();\n  }\n\n  private persistState(): void {\n    // Save current state to file\n    fs.writeFileSync(\n      '.velocity-state.json', \n      JSON.stringify({ pendingReviewLines: this.pendingReviewLines })\n    );\n  }\n\n  private loadConfig(path: string): CapacityConfig {\n    // Load team capacity configuration\n    const config = JSON.parse(fs.readFileSync(path, 'utf8'));\n    return config;\n  }\n\n  private calculatePendingReviewLines(): number {\n    // Implementation to calculate lines of code in PRs\n  }\n\n  private getFileLineCount(filePath: string): number {\n    // Implementation to count lines in a file\n  }\n}\n</code></pre>"},{"location":"antipatterns/velocity-imbalance/#integration-in-cicd-pipeline","title":"Integration in CI/CD Pipeline","text":"<p>Add checks to prevent PR overload:</p> <pre><code># .github/workflows/velocity-check.yml\nname: Velocity Check\n\non:\n  pull_request:\n    types: [opened, synchronize]\n\njobs:\n  check-velocity:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Check team capacity\n        run: |\n          ./analyze-velocity.sh &gt; velocity.txt\n\n          # Get number of open PRs\n          OPEN_PRS=$(gh pr list --json number | jq length)\n\n          # Get maximum recommended PRs\n          MAX_PRS=$(grep \"Target PR count\" velocity.txt | awk '{print $NF}')\n\n          # Check if we're over capacity\n          if (( OPEN_PRS &gt; MAX_PRS )); then\n            echo \"::warning::Team is over review capacity with $OPEN_PRS open PRs (recommended max: $MAX_PRS)\"\n            echo \"Consider waiting for existing PRs to be merged before creating new ones.\"\n          fi\n\n          # Check PR size\n          PR_ADDITIONS=$(gh pr view ${{ github.event.pull_request.number }} --json additions --jq .additions)\n          PR_DELETIONS=$(gh pr view ${{ github.event.pull_request.number }} --json deletions --jq .deletions)\n          PR_SIZE=$((PR_ADDITIONS + PR_DELETIONS))\n\n          MAX_SIZE=$(grep \"Maximum new PR size\" velocity.txt | awk '{print $NF}')\n\n          if (( PR_SIZE &gt; MAX_SIZE )); then\n            echo \"::warning::PR is larger than recommended size ($PR_SIZE lines, recommended max: $MAX_SIZE)\"\n            echo \"Consider breaking this PR into smaller, more focused changes.\"\n          fi\n</code></pre>"},{"location":"antipatterns/velocity-imbalance/#include-in-clinerules","title":"Include in .clinerules","text":"<p>Add velocity management to your <code>.clinerules</code> file:</p> <pre><code>tooling:\n  velocity_management:\n    command: ./analyze-velocity.sh\n    description: \"Check team capacity and review velocity\"\n    when:\n      - \"Before starting a new feature\"\n      - \"When planning work\"\n      - \"Before creating large PRs\"\n      - \"When prioritizing tasks\"\n    examples:\n      - \"./analyze-velocity.sh\"\n\nworkflows:\n  new_feature:\n    steps:\n      - \"Check team velocity and capacity\"\n      - \"Prioritize based on current workload\"\n      - \"Size implementation appropriately\"\n      - \"Break down large features\"\n    tools:\n      - velocity_management\n      - git_workflow\n</code></pre> <p>By implementing these patterns, teams can maintain a healthy balance between AI-powered code generation and human-driven quality processes.</p>"},{"location":"best-practices/","title":"Best Practices for AI-Assisted Coding","text":"<p>This section provides guidelines and patterns for effective collaboration with AI coding assistants. These best practices will help you maintain code quality, manage complexity, and implement robust solutions when working with AI tools.</p>"},{"location":"best-practices/#available-guides","title":"Available Guides","text":""},{"location":"best-practices/#managing-code-complexity","title":"Managing Code Complexity","text":"<p>A comprehensive guide to maintaining optimal code complexity when working with AI coding assistants:</p> <ul> <li>Understanding cyclomatic complexity and its impact</li> <li>Guidelines for optimal code structure</li> <li>Effective prompting techniques for AI assistants</li> <li>Language-specific tools for measuring complexity</li> <li>CI/CD integration for automated complexity checks</li> </ul>"},{"location":"best-practices/#factory-pattern-implementation","title":"Factory Pattern Implementation","text":"<p>A detailed guide to implementing the Factory Pattern for MCP servers with REST API integration:</p> <ul> <li>Core design principles for entity-centric organization</li> <li>Implementation components including abstract base classes</li> <li>Schema definition and validation</li> <li>REST API integration strategies</li> <li>Benefits of the factory-based architecture</li> </ul>"},{"location":"best-practices/#general-principles","title":"General Principles","text":"<p>When working with AI coding assistants, keep these principles in mind:</p> <ol> <li>Maintain control over architecture decisions</li> <li>Use AI for implementation details, not high-level design</li> <li> <p>Validate architectural suggestions against established patterns</p> </li> <li> <p>Verify generated code quality</p> </li> <li>Review all AI-generated code for complexity issues</li> <li> <p>Apply consistent standards to both human and AI-written code</p> </li> <li> <p>Incremental adoption</p> </li> <li>Integrate smaller, well-understood chunks of AI-generated code</li> <li> <p>Build up complexity gradually rather than all at once</p> </li> <li> <p>Continuous learning</p> </li> <li>Document successful patterns for future reference</li> <li> <p>Share effective prompting techniques with your team</p> </li> <li> <p>Balance automation with oversight</p> </li> <li>Automate routine coding tasks with AI</li> <li>Maintain human oversight for critical components</li> </ol>"},{"location":"best-practices/ai-tooling-guide/","title":"AI-Native Developer Tooling: A Guide for Enhancing Agent Productivity","text":""},{"location":"best-practices/ai-tooling-guide/#introduction","title":"Introduction","text":"<p>This guide explores the design and implementation of developer tools specifically optimized for AI coding agents. While traditional developer tools are designed for human developers, AI agents have different strengths, limitations, and information processing patterns that warrant specialized tooling approaches.</p> <p>By creating \"AI-native\" tooling, we can dramatically improve the productivity, accuracy, and effectiveness of AI coding agents, allowing them to produce better code with less developer oversight.</p>"},{"location":"best-practices/ai-tooling-guide/#core-principles-of-ai-native-tooling","title":"Core Principles of AI-Native Tooling","text":""},{"location":"best-practices/ai-tooling-guide/#1-token-efficiency","title":"1. Token Efficiency","text":"<p>AI models process information as tokens, with practical and economic limits on token usage:</p> <ul> <li>Minimize Unnecessary Output: Filter verbose logs, spinners, progress bars, and other human-friendly but token-inefficient outputs</li> <li>Structured Information: Present information in compact, structured formats rather than verbose natural language</li> <li>Incremental Processing: Break large tasks into smaller chunks to avoid context limitations</li> </ul>"},{"location":"best-practices/ai-tooling-guide/#2-deterministic-environments","title":"2. Deterministic Environments","text":"<p>AI agents perform better with predictable, consistent environments:</p> <ul> <li>Reproducible Setups: Ensure identical environments for analysis and execution</li> <li>Version Pinning: Pin dependencies to specific versions to prevent drift</li> <li>Explicit Configuration: Make all configuration explicit rather than depending on inference</li> </ul>"},{"location":"best-practices/ai-tooling-guide/#3-domain-knowledge-accessibility","title":"3. Domain Knowledge Accessibility","text":"<p>Unlike humans, AI agents can't accumulate domain knowledge over time:</p> <ul> <li>Local Context: Provide domain-specific information in the immediate context</li> <li>Searchable References: Create efficient search mechanisms for larger knowledge bases</li> <li>Relationship Graphs: Map connections between domain concepts to enhance understanding</li> </ul>"},{"location":"best-practices/ai-tooling-guide/#4-process-guidance","title":"4. Process Guidance","text":"<p>AI agents benefit from explicit process frameworks:</p> <ul> <li>Decision Trees: Formalize decision points and criteria</li> <li>Standard Patterns: Establish reusable patterns for common tasks</li> <li>Self-validation: Build in mechanisms for the agent to validate its own work</li> </ul>"},{"location":"best-practices/ai-tooling-guide/#ai-native-tooling-patterns","title":"AI-Native Tooling Patterns","text":""},{"location":"best-practices/ai-tooling-guide/#1-log-insulation-layer","title":"1. Log Insulation Layer","text":"<p>Purpose: Shield AI agents from verbose, token-heavy outputs while preserving human readability.</p> <p>Implementation:</p> <pre><code>run_step() {\n    local step_name=$1\n    local log_file=\"$TEMP_DIR/$2.log\"\n    local command=$3\n\n    echo -n \"\u2192 $step_name... \"\n\n    if [ \"$VERBOSE\" = true ]; then\n        # Direct output for humans\n        if eval \"$command\"; then\n            echo -e \"${GREEN}${CHECK_MARK} Success${NC}\"\n            return 0\n        else\n            echo -e \"${RED}${X_MARK} Failed${NC}\"\n            return 1\n        fi\n    else\n        # Redirected output for AI\n        if eval \"$command &gt; '$log_file' 2&gt;&amp;1\"; then\n            echo -e \"${GREEN}${CHECK_MARK} Success${NC} (log: $log_file)\"\n            return 0\n        else\n            echo -e \"${RED}${X_MARK} Failed${NC} (see details in $log_file)\"\n            return 1\n        fi\n    fi\n}\n</code></pre> <p>Benefits: - Reduces token consumption by orders of magnitude - Preserves detailed logs for human debugging - Provides clear success/failure signals to the AI - Scales to any command execution</p>"},{"location":"best-practices/ai-tooling-guide/#2-domain-knowledge-indexing","title":"2. Domain Knowledge Indexing","text":"<p>Purpose: Make domain documentation searchable and accessible to AI agents.</p> <p>Implementation: - Scrape and convert documentation to markdown format - Build a searchable database with full-text indexing - Create simple CLI tools for querying knowledge - Maintain relationship graphs between documents</p> <p>Benefits: - Provides targeted answers to domain questions - Reduces hallucination by offering authoritative references - Enables relationship-based exploration of complex domains - Works offline without requiring constant API access</p>"},{"location":"best-practices/ai-tooling-guide/#3-pre-prompting-with-clinerules","title":"3. Pre-Prompting with .clinerules","text":"<p>Purpose: Direct AI agents to use appropriate tools for specific tasks without manual instruction.</p> <p>Implementation: Create a <code>.clinerules</code> file at the project root:</p> <pre><code>tooling:\n  documentation:\n    command: ./search-docs.sh\n    when: [\"seeking API reference\", \"need domain knowledge\", \"unclear requirements\"]\n    example: \"./search-docs.sh api-authentication\"\n\n  build:\n    command: ./build-local.sh\n    when: [\"need to compile\", \"testing changes\", \"preparing deployment\"]\n    example: \"./build-local.sh --verbose\"\n\n  static_analysis:\n    command: ./analyze-code.sh\n    when: [\"starting new feature\", \"reviewing code\", \"refactoring\"]\n    example: \"./analyze-code.sh src/main.ts\"\n</code></pre> <p>Usage in agent prompt: <pre><code>Before coding, consult the .clinerules file for appropriate tooling for each task.\nFor documentation queries, use ./search-docs.sh instead of making assumptions.\nFor building and testing, use ./build-local.sh to avoid verbose output.\n</code></pre></p> <p>Benefits: - Standardizes tool usage across interactions - Reduces need for repetitive instruction - Enables project-specific workflow optimization - Creates a \"playbook\" the agent can follow</p>"},{"location":"best-practices/ai-tooling-guide/#4-static-analysis-adapters","title":"4. Static Analysis Adapters","text":"<p>Purpose: Translate complex static analysis results into AI-friendly formats.</p> <p>Implementation:</p> <pre><code>// analyze-code.js\nconst executeAnalysis = async (filePath) =&gt; {\n  // Run multiple analysis tools\n  const lintResults = await runEslint(filePath);\n  const typeResults = await runTypeChecker(filePath);\n  const complexityResults = await runComplexityAnalysis(filePath);\n\n  // Synthesize results into AI-friendly format\n  return {\n    issues: summarizeIssues(lintResults, typeResults),\n    complexity: summarizeComplexity(complexityResults),\n    concepts: extractConcepts(filePath),\n    dependencies: analyzeDependencies(filePath),\n    recommendations: generateRecommendations(filePath)\n  };\n};\n</code></pre> <p>Benefits: - Provides pre-processed analysis to guide agent decisions - Highlights important patterns and anti-patterns - Reduces token usage by filtering unnecessary details - Creates a standardized view across multiple tools</p>"},{"location":"best-practices/ai-tooling-guide/#project-specific-ai-tooling-examples","title":"Project-Specific AI Tooling Examples","text":""},{"location":"best-practices/ai-tooling-guide/#1-architecture-pattern-validator","title":"1. Architecture Pattern Validator","text":"<p>Purpose: Enforce approved architectural patterns during development.</p> <p>Implementation:</p> <pre><code>// architecture-validator.ts\nexport class ArchitectureValidator {\n  private readonly patterns: Pattern[];\n\n  constructor(projectRoot: string) {\n    // Load project-specific architectural patterns\n    this.patterns = loadPatternsFromConfig(`${projectRoot}/.archpatterns`);\n  }\n\n  async validate(filePath: string): Promise&lt;ValidationResult&gt; {\n    const fileContent = await fs.readFile(filePath, 'utf8');\n    const ast = parseToAST(fileContent);\n\n    const violations: Violation[] = [];\n\n    // Check each pattern against the AST\n    for (const pattern of this.patterns) {\n      const patternViolations = pattern.check(ast);\n      violations.push(...patternViolations);\n    }\n\n    return {\n      filePath,\n      conformsToArchitecture: violations.length === 0,\n      violations,\n      recommendations: generateRecommendations(violations)\n    };\n  }\n}\n</code></pre> <p>Usage: <pre><code>./validate-architecture.sh src/api/users.ts\n</code></pre></p> <p>Benefits: - Ensures AI-generated code follows established patterns - Provides immediate feedback on architectural violations - Offers specific recommendations for fixing issues - Reduces review cycles by catching issues early</p>"},{"location":"best-practices/ai-tooling-guide/#2-domain-model-extractor","title":"2. Domain Model Extractor","text":"<p>Purpose: Provide AI agents with a clear understanding of domain models and relationships.</p> <p>Implementation:</p> <pre><code>// domain-extractor.ts\nexport class DomainModelExtractor {\n  async extractModels(projectRoot: string): Promise&lt;DomainModel[]&gt; {\n    // Find all model definitions\n    const modelFiles = await findModelFiles(projectRoot);\n\n    // Extract domain models and their relationships\n    const models: DomainModel[] = [];\n\n    for (const file of modelFiles) {\n      const fileContent = await fs.readFile(file, 'utf8');\n      const extractedModels = parseModels(fileContent);\n      models.push(...extractedModels);\n    }\n\n    // Analyze relationships between models\n    const relationships = analyzeRelationships(models);\n\n    return models.map(model =&gt; ({\n      ...model,\n      relationships: relationships.filter(r =&gt; r.source === model.name || r.target === model.name)\n    }));\n  }\n}\n</code></pre> <p>Usage: <pre><code>./extract-domain-models.sh --format=json\n</code></pre></p> <p>Output Example: <pre><code>[\n  {\n    \"name\": \"User\",\n    \"properties\": [\n      {\"name\": \"id\", \"type\": \"UUID\", \"required\": true},\n      {\"name\": \"email\", \"type\": \"String\", \"required\": true},\n      {\"name\": \"role\", \"type\": \"Enum\", \"values\": [\"ADMIN\", \"USER\"]}\n    ],\n    \"relationships\": [\n      {\"type\": \"OneToMany\", \"target\": \"Order\", \"fieldName\": \"orders\"}\n    ]\n  }\n]\n</code></pre></p> <p>Benefits: - Provides clear domain model references - Helps AI understand existing models before extending them - Reduces errors in relationship management - Supports consistent naming patterns</p>"},{"location":"best-practices/ai-tooling-guide/#3-api-contract-validator","title":"3. API Contract Validator","text":"<p>Purpose: Ensure AI-generated code adheres to established API contracts.</p> <p>Implementation:</p> <pre><code>// api-validator.ts\nexport class ApiContractValidator {\n  private readonly contracts: ApiContract[];\n\n  constructor(contractsPath: string) {\n    this.contracts = loadContracts(contractsPath);\n  }\n\n  async validateImplementation(apiImplementationPath: string): Promise&lt;ValidationResult&gt; {\n    const implementation = await parseApiImplementation(apiImplementationPath);\n\n    const violations: Violation[] = [];\n\n    // Check each endpoint against its contract\n    for (const endpoint of implementation.endpoints) {\n      const contract = this.contracts.find(c =&gt; \n        c.method === endpoint.method &amp;&amp; \n        pathMatchesPattern(endpoint.path, c.path)\n      );\n\n      if (!contract) {\n        violations.push({\n          severity: 'ERROR',\n          message: `No contract found for ${endpoint.method} ${endpoint.path}`\n        });\n        continue;\n      }\n\n      // Validate parameters, return types, etc.\n      violations.push(...validateEndpoint(endpoint, contract));\n    }\n\n    return {\n      implementationPath: apiImplementationPath,\n      conformsToContract: violations.length === 0,\n      violations,\n      recommendations: generateRecommendations(violations)\n    };\n  }\n}\n</code></pre> <p>Usage: <pre><code>./validate-api.sh src/controllers/userController.ts\n</code></pre></p> <p>Benefits: - Ensures AI-generated APIs match defined contracts - Prevents breaking changes to public APIs - Provides specific guidance on contract violations - Enforces consistent API design</p>"},{"location":"best-practices/ai-tooling-guide/#implementation-strategy","title":"Implementation Strategy","text":""},{"location":"best-practices/ai-tooling-guide/#starting-small-essential-ai-tooling","title":"Starting Small: Essential AI Tooling","text":"<p>Begin with these foundational tools:</p> <ol> <li>Log Insulation Script: Create wrapper scripts for build, test, and deployment commands</li> <li>Domain Documentation Indexer: Convert project documentation to searchable markdown</li> <li>.clinerules File: Define basic rules for when to use each tool</li> <li>Simplified Static Analysis: Create a basic analysis script that highlights key issues</li> </ol>"},{"location":"best-practices/ai-tooling-guide/#evolving-your-tooling","title":"Evolving Your Tooling","text":"<p>As you work with AI agents more extensively:</p> <ol> <li>Track Pain Points: Note where AI agents consistently struggle</li> <li>Measure Token Usage: Identify high-token-consumption workflows</li> <li>Standardize Patterns: Create templates for common development tasks</li> <li>Build Custom Validators: Develop project-specific validation tools</li> </ol>"},{"location":"best-practices/ai-tooling-guide/#integration-with-workflow","title":"Integration with Workflow","text":"<p>For optimal results:</p> <ol> <li>Include in Onboarding: Mention available tools in your initial prompt</li> <li>Consistent References: Use consistent tool names across conversations</li> <li>Tool Chaining: Design tools to work together through standardized outputs</li> <li>Feedback Loop: Refine tools based on agent performance</li> </ol>"},{"location":"best-practices/ai-tooling-guide/#implementing-a-clinerules-approach","title":"Implementing a .clinerules Approach","text":""},{"location":"best-practices/ai-tooling-guide/#create-a-basic-clinerules-file","title":"Create a Basic .clinerules File","text":"<pre><code># .clinerules - AI agent tooling guidance\ntooling:\n  # Documentation and knowledge tools\n  domain_knowledge:\n    command: ./search-docs.sh\n    description: \"Search project-specific documentation\"\n    when: \n      - \"Looking for project-specific concepts\"\n      - \"Researching API details\"\n      - \"Seeking implementation examples\"\n    examples:\n      - \"./search-docs.sh authentication\"\n      - \"./search-docs.sh -t 'API Reference'\"\n\n  # Build and test tools\n  build:\n    command: ./build-local.sh\n    description: \"Build the project with reduced output noise\"\n    when:\n      - \"Compiling code\"\n      - \"Preparing for tests\"\n      - \"Verifying changes\"\n    examples:\n      - \"./build-local.sh\"\n      - \"./build-local.sh --verbose\"\n\n  # Analysis tools\n  static_analysis:\n    command: ./analyze-code.sh\n    description: \"Run static analysis on code files\"\n    when:\n      - \"Starting a new component\"\n      - \"Reviewing existing code\"\n      - \"Refactoring\"\n    examples:\n      - \"./analyze-code.sh src/component.ts\"\n      - \"./analyze-code.sh --fix src/component.ts\"\n\n  domain_model:\n    command: ./extract-domain-model.sh\n    description: \"Extract domain model information\"\n    when:\n      - \"Working with data models\"\n      - \"Designing new entities\"\n      - \"Extending existing models\"\n    examples:\n      - \"./extract-domain-model.sh\"\n      - \"./extract-domain-model.sh User Order\"\n\nworkflows:\n  new_feature:\n    steps:\n      - \"Search docs for related concepts\"\n      - \"Extract relevant domain models\"\n      - \"Run static analysis on related components\"\n      - \"Create implementation following factory pattern\"\n      - \"Build and validate implementation\"\n    tools:\n      - domain_knowledge\n      - domain_model\n      - static_analysis\n      - build\n</code></pre>"},{"location":"best-practices/ai-tooling-guide/#add-pre-prompt-instructions","title":"Add Pre-prompt Instructions","text":"<p>Include these instructions in your initial prompt to the AI agent:</p> <pre><code>This project uses AI-optimized tooling for development tasks. At the start of our session, please:\n\n1. Review the .clinerules file at the project root to understand available tools\n2. Use the specified tools for domain knowledge, code analysis, and building\n3. Follow established workflows for common tasks\n4. Default to using project tools rather than suggesting manual approaches\n\nFor any area where you're uncertain about domain details, use ./search-docs.sh before making assumptions.\n</code></pre>"},{"location":"best-practices/ai-tooling-guide/#additional-ai-native-development-patterns","title":"Additional AI-Native Development Patterns","text":"<p>Beyond the core tooling approaches, several complementary patterns can enhance AI agent productivity across projects of different sizes and complexities.</p>"},{"location":"best-practices/ai-tooling-guide/#1-context-compression-mechanisms","title":"1. Context Compression Mechanisms","text":"<p>Purpose: Reduce token consumption when working with large codebases.</p> <p>Implementation:</p> <pre><code>// context-compressor.ts\nexport class ContextCompressor {\n  compress(files: string[], topic: string): CompressedContext {\n    // Identify relevant code sections based on topic\n    const relevantParts = this.findRelevantCodeParts(files, topic);\n\n    // Create semantic summaries of modules\n    const moduleSummaries = this.generateModuleSummaries(files);\n\n    // Extract key interfaces and types\n    const interfaces = this.extractInterfaces(files);\n\n    return {\n      relevantCode: relevantParts,\n      moduleSummaries,\n      interfaces,\n      totalSizeReduction: this.calculateReduction(files, relevantParts)\n    };\n  }\n\n  private findRelevantCodeParts(files: string[], topic: string): CodePart[] {\n    // Implementation details...\n  }\n\n  // Additional helper methods...\n}\n</code></pre> <p>Usage: <pre><code>./compress-context.sh --topic=\"user authentication\" --files=\"src/auth/**/*.ts\"\n</code></pre></p> <p>Benefits: - Makes large codebases manageable for AI context windows - Focuses attention on relevant components - Provides necessary context without overwhelming the agent - Scales to enterprise-level projects</p>"},{"location":"best-practices/ai-tooling-guide/#2-design-pattern-templates","title":"2. Design Pattern Templates","text":"<p>Purpose: Guide AI agents to implement consistent design patterns.</p> <p>Implementation: Create a directory of pattern templates: <pre><code>patterns/\n\u251c\u2500\u2500 factory/\n\u2502   \u251c\u2500\u2500 template.ts\n\u2502   \u251c\u2500\u2500 example.ts\n\u2502   \u2514\u2500\u2500 usage.md\n\u251c\u2500\u2500 repository/\n\u2502   \u251c\u2500\u2500 template.ts\n\u2502   \u251c\u2500\u2500 example.ts\n\u2502   \u2514\u2500\u2500 usage.md\n\u2514\u2500\u2500 ...\n</code></pre></p> <p>Sample factory pattern template: <pre><code>// patterns/factory/template.ts\nexport interface {{EntityName}} {\n  // Entity interface\n}\n\nexport interface {{EntityName}}Factory {\n  create{{EntityName}}(params: {{CreateParams}}): {{EntityName}};\n}\n\nexport class Default{{EntityName}}Factory implements {{EntityName}}Factory {\n  constructor(\n    // Dependencies\n  ) {}\n\n  create{{EntityName}}(params: {{CreateParams}}): {{EntityName}} {\n    // Implementation\n  }\n}\n</code></pre></p> <p>Usage: <pre><code>./apply-pattern.sh factory EntityName=User CreateParams=UserCreationParams\n</code></pre></p> <p>Benefits: - Ensures consistent pattern implementation - Reduces design decisions for common patterns - Provides working examples for reference - Enforces architectural guidelines</p>"},{"location":"best-practices/ai-tooling-guide/#3-code-generation-validators","title":"3. Code Generation Validators","text":"<p>Purpose: Validate AI-generated code against project standards before integration.</p> <p>Implementation:</p> <pre><code>// validation-pipeline.ts\nexport class ValidationPipeline {\n  private validators: Validator[];\n\n  constructor() {\n    this.validators = [\n      new StyleGuideValidator(),\n      new ArchitectureValidator(),\n      new SecurityValidator(),\n      new TestCoverageValidator(),\n      new PerformanceValidator()\n    ];\n  }\n\n  async validate(generatedCode: string): Promise&lt;ValidationResult&gt; {\n    const results: ValidationStepResult[] = [];\n\n    for (const validator of this.validators) {\n      const result = await validator.validate(generatedCode);\n      results.push(result);\n\n      // Stop on critical failures\n      if (result.severity === 'critical' &amp;&amp; !result.passed) {\n        break;\n      }\n    }\n\n    const passed = results.every(r =&gt; r.passed);\n\n    return {\n      passed,\n      results,\n      suggestions: this.generateSuggestions(results)\n    };\n  }\n\n  private generateSuggestions(results: ValidationStepResult[]): string[] {\n    // Generate actionable suggestions based on results\n  }\n}\n</code></pre> <p>Usage: <pre><code>./validate-generated.sh --file=src/generated-component.ts\n</code></pre></p> <p>Benefits: - Catches issues before human review - Provides actionable feedback for improvement - Enforces project standards automatically - Reduces review cycles</p>"},{"location":"best-practices/ai-tooling-guide/#4-entity-relationship-visualization","title":"4. Entity Relationship Visualization","text":"<p>Purpose: Generate visual representations of complex domain models for AI comprehension.</p> <p>Implementation:</p> <pre><code>// er-visualizer.ts\nexport class EntityRelationshipVisualizer {\n  async visualize(modelPaths: string[]): Promise&lt;string&gt; {\n    // Extract entities and relationships\n    const entities = await this.extractEntities(modelPaths);\n    const relationships = await this.extractRelationships(modelPaths);\n\n    // Generate Mermaid diagram\n    return this.generateMermaidDiagram(entities, relationships);\n  }\n\n  private async extractEntities(modelPaths: string[]): Promise&lt;Entity[]&gt; {\n    // Implementation\n  }\n\n  private async extractRelationships(modelPaths: string[]): Promise&lt;Relationship[]&gt; {\n    // Implementation\n  }\n\n  private generateMermaidDiagram(entities: Entity[], relationships: Relationship[]): string {\n    let diagram = 'erDiagram\\n';\n\n    // Add entities\n    for (const entity of entities) {\n      diagram += `  ${entity.name} {\\n`;\n\n      // Add attributes\n      for (const attribute of entity.attributes) {\n        diagram += `    ${attribute.type} ${attribute.name}\\n`;\n      }\n\n      diagram += '  }\\n';\n    }\n\n    // Add relationships\n    for (const rel of relationships) {\n      diagram += `  ${rel.source} ${this.mapCardinalitySymbol(rel.sourceCardinality)} -- ${this.mapCardinalitySymbol(rel.targetCardinality)} ${rel.target} : \"${rel.description}\"\\n`;\n    }\n\n    return diagram;\n  }\n\n  private mapCardinalitySymbol(cardinality: Cardinality): string {\n    // Implementation\n  }\n}\n</code></pre> <p>Usage: <pre><code>./visualize-model.sh src/models/\n</code></pre></p> <p>Benefits: - Creates visual understanding of complex relationships - Simplifies domain comprehension - Highlights potential domain inconsistencies - Generates reference material for documentation</p>"},{"location":"best-practices/ai-tooling-guide/#5-test-case-coverage-explorer","title":"5. Test Case Coverage Explorer","text":"<p>Purpose: Help AI agents understand existing test patterns and coverage.</p> <p>Implementation:</p> <pre><code>// test-explorer.ts\nexport class TestCoverageExplorer {\n  async explore(sourcePath: string): Promise&lt;TestCoverageReport&gt; {\n    // Analyze source code\n    const sourceAnalysis = await this.analyzeSource(sourcePath);\n\n    // Find corresponding tests\n    const tests = await this.findCorrespondingTests(sourcePath);\n\n    // Analyze test coverage\n    const coverage = await this.analyzeTestCoverage(sourcePath, tests);\n\n    // Generate patterns from tests\n    const patterns = await this.extractTestPatterns(tests);\n\n    return {\n      sourcePath,\n      tests,\n      coverage,\n      untested: this.findUntestedCode(sourceAnalysis, coverage),\n      patterns\n    };\n  }\n\n  // Helper methods...\n}\n</code></pre> <p>Usage: <pre><code>./explore-tests.sh src/services/userService.ts\n</code></pre></p> <p>Benefits: - Shows AI agents how to test specific components - Identifies gaps in test coverage - Extracts project-specific testing patterns - Ensures consistency with existing test approaches</p>"},{"location":"best-practices/ai-tooling-guide/#6-complexity-budget-enforcer","title":"6. Complexity Budget Enforcer","text":"<p>Purpose: Prevent AI agents from generating overly complex solutions.</p> <p>Implementation:</p> <pre><code>// complexity-budget.ts\nexport class ComplexityBudgetEnforcer {\n  private readonly budgets: Record&lt;string, ComplexityBudget&gt;;\n\n  constructor(configPath: string) {\n    this.budgets = this.loadBudgetsFromConfig(configPath);\n  }\n\n  analyze(code: string, path: string): ComplexityAnalysis {\n    // Determine which budget applies\n    const budget = this.findApplicableBudget(path);\n\n    // Analyze actual complexity\n    const actual = this.calculateComplexity(code);\n\n    // Check if within budget\n    const within = this.isWithinBudget(actual, budget);\n\n    return {\n      path,\n      budget,\n      actual,\n      within,\n      recommendations: !within ? this.generateRecommendations(actual, budget) : []\n    };\n  }\n\n  private loadBudgetsFromConfig(path: string): Record&lt;string, ComplexityBudget&gt; {\n    // Implementation\n  }\n\n  // Helper methods...\n}\n</code></pre> <p>Example config: <pre><code>{\n  \"default\": {\n    \"cyclomatic\": 10,\n    \"depth\": 3,\n    \"parameters\": 4,\n    \"length\": 100\n  },\n  \"controllers\": {\n    \"cyclomatic\": 5,\n    \"depth\": 2,\n    \"parameters\": 3,\n    \"length\": 50\n  }\n}\n</code></pre></p> <p>Usage: <pre><code>./check-complexity.sh src/generated-file.ts\n</code></pre></p> <p>Benefits: - Prevents complexity creep - Enforces different standards for different component types - Provides concrete recommendations for simplification - Catches complexity issues early</p>"},{"location":"best-practices/ai-tooling-guide/#patterns-for-scale-from-small-to-large-projects","title":"Patterns for Scale: From Small to Large Projects","text":""},{"location":"best-practices/ai-tooling-guide/#for-small-projects-1-5-developers","title":"For Small Projects (1-5 developers)","text":"<ol> <li>Simplified Toolchain:</li> <li>Focus on log insulation and basic documentation access</li> <li>Use .clinerules with emphasis on simplicity</li> <li> <p>Implement lightweight static analysis</p> </li> <li> <p>Progressive Enhancement:</p> </li> <li>Start with manual analysis and gradually automate</li> <li>Prioritize domain model understanding</li> <li> <p>Use minimal architectural enforcement</p> </li> <li> <p>Key Tools to Implement First:</p> </li> <li><code>./build-local.sh</code> for build insulation</li> <li><code>./search-docs.sh</code> for documentation access</li> <li>Basic <code>.clinerules</code> file with 3-5 core tools</li> </ol>"},{"location":"best-practices/ai-tooling-guide/#for-medium-projects-5-20-developers","title":"For Medium Projects (5-20 developers)","text":"<ol> <li>Standardized Workflows:</li> <li>Create workflow definitions in <code>.clinerules</code></li> <li>Implement domain model extractors</li> <li> <p>Add test coverage exploration</p> </li> <li> <p>Team Coordination:</p> </li> <li>Share AI prompt templates between team members</li> <li>Standardize architecture validation rules</li> <li> <p>Implement design pattern templates</p> </li> <li> <p>Key Tools to Implement First:</p> </li> <li>Domain model visualization</li> <li>Architectural pattern validation</li> <li>Test coverage explorer</li> <li>Context compression for larger codebases</li> </ol>"},{"location":"best-practices/ai-tooling-guide/#for-large-projects-20-developers","title":"For Large Projects (20+ developers)","text":"<ol> <li>Enterprise Integration:</li> <li>Connect AI tooling with existing CI/CD pipelines</li> <li>Implement comprehensive validation pipelines</li> <li> <p>Create domain-specific language tooling</p> </li> <li> <p>Governance and Standards:</p> </li> <li>Enforce complexity budgets based on component types</li> <li>Implement security and compliance validation</li> <li> <p>Maintain pattern libraries with versioning</p> </li> <li> <p>Key Tools to Implement First:</p> </li> <li>Context compression for monorepo navigation</li> <li>Advanced architectural validation</li> <li>Complexity budget enforcement</li> <li>Security and compliance validation</li> </ol>"},{"location":"best-practices/ai-tooling-guide/#conclusion","title":"Conclusion","text":"<p>AI-native developer tooling represents a significant opportunity to enhance the effectiveness of AI coding agents. By designing tools that address the specific needs and limitations of AI models, we can achieve:</p> <ul> <li>Higher Quality Output: Better-informed agents produce better code</li> <li>Reduced Review Cycles: Catch issues before they reach human review</li> <li>Consistent Architecture: Enforce architectural patterns automatically</li> <li>Domain Knowledge Integration: Provide agents with necessary context</li> </ul> <p>The patterns described in this guide can be adapted to projects of any size. Start with the foundational approaches that address your immediate pain points, then gradually expand your tooling ecosystem as your experience with AI agents grows.</p> <p>Remember that effective AI tooling should evolve alongside your project and your team's workflow. Regularly evaluate which tools provide the most value and be willing to refine your approach based on real-world experience.</p> <p>By investing in AI-native tooling, you'll create a development environment where AI agents can truly shine as productive members of your development team.</p>"},{"location":"best-practices/collaborative-workflow-integration/","title":"Collaborative Workflow Integration","text":"<p>When AI agents fail to integrate with the team's collaborative workflow and version control practices. Instead of respecting the social contract between developers, the agent generates code without consideration for branching strategies, commit conventions, pull request workflows, or the pace of integration.</p>"},{"location":"best-practices/collaborative-workflow-integration/#how-to-spot-it","title":"How to Spot It","text":"<p>Look for these signs:</p> <ul> <li>Generating large volumes of code without a clear integration strategy</li> <li>Ignoring branch naming conventions or branching strategies</li> <li>Creating sweeping changes across multiple components simultaneously</li> <li>Disregarding established commit message conventions</li> <li>Proposing changes without consideration for ongoing work</li> <li>Overlooking code review processes and expectations</li> <li>Failing to consider the team's velocity and integration capacity</li> </ul>"},{"location":"best-practices/collaborative-workflow-integration/#why-its-harmful","title":"Why It's Harmful","text":"<ul> <li>Creates merge conflicts and integration challenges</li> <li>Overwhelms code review processes with too much code</li> <li>Disrupts team coordination and planning</li> <li>Makes change history difficult to track and understand</li> <li>Reduces visibility into the purpose and context of changes</li> <li>Increases the risk of breaking existing functionality</li> <li>Leads to solution sprawl that's difficult to test and validate</li> </ul>"},{"location":"best-practices/collaborative-workflow-integration/#what-to-do-about-it","title":"What to Do About It","text":"<p>When you see this happening:</p> <ol> <li>Say \"Let's consider how this fits into our team's workflow and branching strategy.\"</li> <li>Ask \"How should we break this down into manageable, reviewable commits?\"</li> <li>Clarify: \"Our team uses this specific git workflow\u2014let's plan how these changes align with it.\"</li> <li>Suggest: \"We should coordinate this with other ongoing work on related components.\"</li> </ol> <p>To prevent it next time:</p> <ol> <li>Create git workflow guides specific to your team's practices</li> <li>Implement commit message validators that enforce conventions</li> <li>Build branch naming and structure tools</li> <li>Develop change size estimators that suggest appropriate scoping</li> <li>Add PR preparation tools that organize changes for effective review</li> </ol>"},{"location":"best-practices/collaborative-workflow-integration/#example","title":"Example","text":"<p>AI: \"Here's a complete implementation that refactors the authentication system, user profile management, and database schema.\"</p> <p>You: \"This is valuable work, but we need to break it down into manageable pieces that align with our git workflow. Let's create a feature branch for authentication changes first, following our branching convention of 'feature/auth-refactor', and prepare a focused PR that our team can review effectively. Then we can address the other components as separate PRs.\"</p>"},{"location":"best-practices/collaborative-workflow-integration/#benefits-of-fixing-this","title":"Benefits of Fixing This","text":"<ul> <li>Smoother integration of AI-generated code</li> <li>Respect for the team's social contract and workflow</li> <li>Better alignment with review capacity and processes</li> <li>Clearer change history and commit messages</li> <li>Reduced risk of breaking changes or conflicts</li> <li>More effective collaboration between AI and human developers</li> <li>Sustainable pace of code integration</li> </ul>"},{"location":"best-practices/collaborative-workflow-integration/#implementing-ai-aware-git-workflows","title":"Implementing AI-Aware Git Workflows","text":""},{"location":"best-practices/collaborative-workflow-integration/#git-tool-integration","title":"Git Tool Integration","text":"<p>Create wrappers for common git operations that provide AI agents with project-specific context:</p> <pre><code>#!/bin/bash\n# ai-git-helper.sh\n\naction=$1\nshift\n\ncase $action in\n  \"branch-for\")\n    # Suggest appropriate branch name for a feature\n    feature_description=$1\n    convention=$(cat .git-conventions.json | jq -r '.branchNaming')\n    echo \"Suggested branch name: $(./format-branch-name.sh \"$convention\" \"$feature_description\")\"\n    ;;\n\n  \"commit-scope\")\n    # List valid commit scopes for the project\n    cat .git-conventions.json | jq -r '.commitScopes[]'\n    ;;\n\n  \"prepare-pr\")\n    # Structure changes for a PR\n    branch_name=$(git rev-parse --abbrev-ref HEAD)\n    template=$(cat .github/PULL_REQUEST_TEMPLATE.md)\n    echo \"PR Title: $(./suggest-pr-title.sh \"$branch_name\")\"\n    echo \"PR Template: $template\"\n    ;;\n\n  \"team-velocity\")\n    # Show team's recent integration velocity\n    ./analyze-velocity.sh\n    ;;\n\n  \"change-impact\")\n    # Analyze impact of changes in specified files\n    ./analyze-change-impact.sh $@\n    ;;\n\n  *)\n    echo \"Unknown action: $action\"\n    exit 1\n    ;;\nesac\n</code></pre>"},{"location":"best-practices/collaborative-workflow-integration/#git-conventionsjson","title":".git-conventions.json","text":"<p>Create a structured representation of your team's git conventions:</p> <pre><code>{\n  \"branchNaming\": {\n    \"feature\": \"feature/{kebab-case-description}\",\n    \"bugfix\": \"bugfix/{issue-number}-{kebab-case-description}\",\n    \"hotfix\": \"hotfix/{kebab-case-description}\",\n    \"release\": \"release/{semver-version}\"\n  },\n  \"commitMessage\": {\n    \"format\": \"{scope}: {type}({optional-ticket}) {imperative-description}\",\n    \"examples\": [\n      \"feat(auth): add multi-factor authentication\",\n      \"fix(JIRA-123): resolve user session timeout issue\",\n      \"chore: update dependencies to latest versions\"\n    ]\n  },\n  \"commitScopes\": [\n    \"auth\", \"api\", \"ui\", \"db\", \"config\", \"docs\", \"tests\", \"ci\", \"deps\"\n  ],\n  \"commitTypes\": [\n    \"feat\", \"fix\", \"docs\", \"style\", \"refactor\", \"test\", \"chore\", \"revert\"\n  ],\n  \"prWorkflow\": {\n    \"requiredApprovals\": 2,\n    \"targetReviewTimeHours\": 24,\n    \"maxLinesPerPR\": 500,\n    \"requiredChecks\": [\"lint\", \"build\", \"test\"]\n  }\n}\n</code></pre>"},{"location":"best-practices/collaborative-workflow-integration/#github-cli-integration","title":"GitHub CLI Integration","text":"<p>For GitHub-based projects, create AI-friendly GitHub CLI wrappers:</p> <pre><code>#!/bin/bash\n# ai-gh-helper.sh\n\naction=$1\nshift\n\ncase $action in\n  \"list-issues\")\n    # List open issues with labels and assignees\n    gh issue list --state open --limit 50 --json number,title,labels,assignees \\\n      | jq 'map({number, title, labels: [.labels[].name], assignees: [.assignees[].login]})'\n    ;;\n\n  \"suggest-issue\")\n    # Suggest issues related to a specific component\n    component=$1\n    gh issue list --state open --label \"$component\" --json number,title,labels \\\n      | jq 'map({number, title, labels: [.labels[].name]})'\n    ;;\n\n  \"pr-status\")\n    # Show status of PRs and reviews\n    gh pr list --state open --json number,title,author,reviewRequests,reviews \\\n      | jq 'map({number, title, author: .author.login, reviewers: [.reviewRequests[].login], reviewStatus: [.reviews[].state]})'\n    ;;\n\n  \"create-pr\")\n    # Create a PR with proper formatting\n    title=$1\n    body=$2\n    gh pr create --title \"$title\" --body \"$body\"\n    ;;\n\n  *)\n    echo \"Unknown action: $action\"\n    exit 1\n    ;;\nesac\n</code></pre>"},{"location":"best-practices/collaborative-workflow-integration/#guidance-in-clinerules","title":"Guidance in .clinerules","text":"<p>Add a git workflow section to your <code>.clinerules</code> file:</p> <pre><code>tooling:\n  # Git workflow tools\n  git_workflow:\n    command: ./ai-git-helper.sh\n    description: \"Work with team's git conventions and workflow\"\n    when:\n      - \"Starting a new feature or task\"\n      - \"Preparing code for review\"\n      - \"Creating commits\"\n      - \"Evaluating change impact\"\n    examples:\n      - \"./ai-git-helper.sh branch-for 'add user authentication'\"\n      - \"./ai-git-helper.sh commit-scope\"\n      - \"./ai-git-helper.sh prepare-pr\"\n      - \"./ai-git-helper.sh team-velocity\"\n\n  github_workflow:\n    command: ./ai-gh-helper.sh\n    description: \"Work with GitHub issues, PRs, and reviews\"\n    when:\n      - \"Finding suitable tasks\"\n      - \"Creating or updating PRs\"\n      - \"Checking review status\"\n    examples:\n      - \"./ai-gh-helper.sh list-issues\"\n      - \"./ai-gh-helper.sh suggest-issue auth\"\n      - \"./ai-gh-helper.sh pr-status\"\n\nworkflows:\n  new_feature:\n    steps:\n      - \"Identify appropriate issue\"\n      - \"Create feature branch using conventions\"\n      - \"Break implementation into manageable commits\"\n      - \"Ensure tests and documentation\"\n      - \"Prepare PR with appropriate scope\"\n    tools:\n      - github_workflow\n      - git_workflow\n      - static_analysis\n      - build\n</code></pre> <p>By implementing these tools and conventions, AI agents can become better team players that work harmoniously with established development practices.</p>"},{"location":"best-practices/cyclomatic-complexity/","title":"Managing Code Complexity: A Guide for Working with AI Coding Agents","text":""},{"location":"best-practices/cyclomatic-complexity/#introduction","title":"Introduction","text":"<p>This guide provides practical strategies for maintaining optimal code complexity when working with AI coding assistants. It covers complexity metrics, language-specific tools, and prompting techniques to ensure that AI-generated code remains maintainable, testable, and robust.</p>"},{"location":"best-practices/cyclomatic-complexity/#understanding-cyclomatic-complexity","title":"Understanding Cyclomatic Complexity","text":"<p>Cyclomatic complexity measures the number of independent paths through a program's code. It provides a quantitative assessment of code complexity.</p>"},{"location":"best-practices/cyclomatic-complexity/#how-its-calculated","title":"How It's Calculated","text":"<ul> <li>Starting value: 1</li> <li>Add 1 for each:</li> <li><code>if</code> statement</li> <li><code>else if</code> statement</li> <li><code>case</code> in a <code>switch</code></li> <li>Boolean operator (<code>&amp;&amp;</code>, <code>||</code>) in conditions</li> <li>Loop (<code>for</code>, <code>while</code>, <code>do-while</code>)</li> <li><code>catch</code> block</li> </ul>"},{"location":"best-practices/cyclomatic-complexity/#complexity-thresholds","title":"Complexity Thresholds","text":"Complexity Risk Level Recommendation 1-10 Low Ideal target range for most functions 11-20 Moderate Consider refactoring 21-50 High Requires immediate refactoring 50+ Very High Untestable, must be broken down"},{"location":"best-practices/cyclomatic-complexity/#guidelines-for-optimal-code-structure","title":"Guidelines for Optimal Code Structure","text":""},{"location":"best-practices/cyclomatic-complexity/#function-design","title":"Function Design","text":"<ul> <li>Size: Keep functions under 30 lines of code</li> <li>Responsibility: One function = one responsibility</li> <li>Complexity: Target maximum cyclomatic complexity of 10</li> <li>Parameters: Limit to 3-4 parameters per function</li> <li>Return statements: Use early returns for edge cases</li> </ul>"},{"location":"best-practices/cyclomatic-complexity/#conditional-logic","title":"Conditional Logic","text":"<ul> <li>Nesting: Maximum 2-3 levels of nested conditionals</li> <li>Complex conditions: Extract into named helper functions or variables</li> <li>Decision making: Use switch statements instead of long if-else chains</li> <li>Validation: Handle edge cases and validation at the beginning of functions</li> </ul>"},{"location":"best-practices/cyclomatic-complexity/#code-organization","title":"Code Organization","text":"<ul> <li>Modules: Each file should have a clear, single purpose</li> <li>Interfaces: Design clean, minimal public interfaces</li> <li>Dependencies: Reduce coupling between components</li> <li>Patterns: Apply consistent patterns for similar problems</li> </ul>"},{"location":"best-practices/cyclomatic-complexity/#prompting-ai-coding-agents","title":"Prompting AI Coding Agents","text":"<p>When working with AI coding assistants, include these specific instructions in your prompts:</p>"},{"location":"best-practices/cyclomatic-complexity/#general-prompting-template","title":"General Prompting Template","text":"<pre><code>[Describe the task]\n\nPlease follow these complexity guidelines:\n- Keep functions under 30 lines with cyclomatic complexity under 10\n- One function = one responsibility\n- Maximum 2-3 levels of nesting\n- Extract complex conditions into named helper functions\n- Use early returns for validation and edge cases\n- Include brief comments explaining complex logic\n</code></pre>"},{"location":"best-practices/cyclomatic-complexity/#for-refactoring-tasks","title":"For Refactoring Tasks","text":"<pre><code>Please refactor this code to:\n- Break up functions with complexity over 10\n- Extract helper functions for repeated or complex logic\n- Reduce nesting depth\n- Make the code more testable\n</code></pre>"},{"location":"best-practices/cyclomatic-complexity/#for-code-reviews","title":"For Code Reviews","text":"<pre><code>Review this code focusing on complexity issues:\n- Identify functions with high cyclomatic complexity\n- Suggest refactoring for nested conditionals\n- Check for functions with too many responsibilities\n- Look for opportunities to extract helper methods\n</code></pre>"},{"location":"best-practices/cyclomatic-complexity/#language-specific-tools-for-measuring-complexity","title":"Language-Specific Tools for Measuring Complexity","text":""},{"location":"best-practices/cyclomatic-complexity/#python","title":"Python","text":"<ol> <li> <p>Radon - Command-line tool and Python API    <pre><code>pip install radon\nradon cc path/to/file.py --min B\n</code></pre></p> </li> <li> <p>Pylint - Linting with complexity checks    <pre><code>pip install pylint\npylint --max-complexity=10 path/to/file.py\n</code></pre></p> </li> <li> <p>Wily - Tracks complexity over time    <pre><code>pip install wily\nwily build path/to/codebase\nwily report path/to/file.py\n</code></pre></p> </li> </ol>"},{"location":"best-practices/cyclomatic-complexity/#typescriptjavascript","title":"TypeScript/JavaScript","text":"<ol> <li>ESLint with complexity plugin <pre><code>npm install eslint eslint-plugin-complexity\n</code></pre></li> </ol> <p>In <code>.eslintrc.json</code>:    <pre><code>{\n  \"plugins\": [\"complexity\"],\n  \"rules\": {\n    \"complexity\": [\"error\", 10]\n  }\n}\n</code></pre></p> <ol> <li>CodeClimate - Quality monitoring tool</li> <li>Set up through the CodeClimate platform</li> <li> <p>Integrates with GitHub for automated reviews</p> </li> <li> <p>Plato - JavaScript complexity reporting    <pre><code>npm install -g plato\nplato -r -d report path/to/source\n</code></pre></p> </li> </ol>"},{"location":"best-practices/cyclomatic-complexity/#rust","title":"Rust","text":"<ol> <li> <p>Clippy - Official Rust linter    <pre><code>rustup component add clippy\ncargo clippy\n</code></pre></p> </li> <li> <p>Rust-code-analysis - Mozilla's metrics tool    <pre><code>cargo install rust-code-analysis-cli\nrust-code-analysis-cli -p path/to/src -o metrics.json\n</code></pre></p> </li> </ol>"},{"location":"best-practices/cyclomatic-complexity/#cicd-integration","title":"CI/CD Integration","text":"<p>Add complexity checking to your continuous integration pipeline:</p>"},{"location":"best-practices/cyclomatic-complexity/#github-actions-example","title":"GitHub Actions Example","text":"<pre><code>name: Code Quality\n\non: [push, pull_request]\n\njobs:\n  complexity:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Set up Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: '3.x'\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install radon\n\n      - name: Check cyclomatic complexity\n        run: |\n          radon cc --min C . &gt; complexity_report.txt\n          if grep -q \"^[EF]\" complexity_report.txt; then\n            echo \"High complexity code detected:\"\n            cat complexity_report.txt\n            exit 1\n          fi\n</code></pre>"},{"location":"best-practices/cyclomatic-complexity/#best-practices-for-ai-generated-code-review","title":"Best Practices for AI-Generated Code Review","text":"<ol> <li>Immediate review - Always review AI-generated code before integration</li> <li>Complexity check - Run complexity tools on generated code</li> <li>Understanding - Ensure you understand every line generated</li> <li>Test coverage - Write tests that cover all paths through the code</li> <li>Incremental adoption - Integrate smaller, well-understood chunks</li> </ol>"},{"location":"best-practices/cyclomatic-complexity/#conclusion","title":"Conclusion","text":"<p>Maintaining optimal code complexity is crucial for long-term project health. By following these guidelines and using appropriate tools, you can work effectively with AI coding agents to produce clean, maintainable, and robust code.</p> <p>Remember that complexity metrics are guidelines, not strict rules. Balance them with readability, performance requirements, and the specific context of your project.</p>"},{"location":"best-practices/factory-pattern/","title":"Factory Pattern Implementation Guide for MCP Servers with REST API","text":""},{"location":"best-practices/factory-pattern/#core-design-principles","title":"Core Design Principles","text":"<ol> <li> <p>Entity-Centric Organization: Structure your tools around domain entities rather than individual operations.</p> </li> <li> <p>Operation Grouping: Each entity tool should support multiple related operations (list, get, create, update, delete).</p> </li> <li> <p>Factory-Based Creation: Implement a central factory that creates and configures entity tools.</p> </li> <li> <p>Registry-Based Management: Use a tool registry to manage registration, discovery, and execution.</p> </li> <li> <p>Declarative Schema Definition: Define operation parameters using declarative schemas for validation and documentation.</p> </li> </ol>"},{"location":"best-practices/factory-pattern/#implementation-components","title":"Implementation Components","text":""},{"location":"best-practices/factory-pattern/#1-abstract-base-class","title":"1. Abstract Base Class","text":"<pre><code>abstract class EntityTool {\n  protected operations: Record&lt;string, Function&gt; = {};\n  protected schemas: Record&lt;string, Schema&gt; = {};\n\n  // Register operations with their validation schemas\n  protected registerOperation(name: string, handler: Function, schema: Schema): void {\n    this.operations[name] = handler;\n    this.schemas[name] = schema;\n  }\n\n  // Execute operations with validation\n  public async execute(args: any): Promise&lt;any&gt; {\n    const operation = args.operation;\n    const params = args[`${operation}Params`];\n\n    // Validate params using schema\n    const validParams = this.schemas[operation].parse(params);\n\n    // Execute operation\n    return this.operations[operation](validParams);\n  }\n\n  // Generate documentation\n  public getDocumentation(): Documentation {\n    // Implementation\n  }\n}\n</code></pre>"},{"location":"best-practices/factory-pattern/#2-entity-tool-factory","title":"2. Entity Tool Factory","text":"<pre><code>class EntityToolFactory {\n  // Create instance of UsersTool\n  static createUsersTool(apiClient: ApiClient): UsersTool {\n    return new UsersTool(apiClient);\n  }\n\n  // Create instance of ResourcesTool\n  static createResourcesTool(apiClient: ApiClient): ResourcesTool {\n    return new ResourcesTool(apiClient);\n  }\n\n  // Other factory methods...\n}\n</code></pre>"},{"location":"best-practices/factory-pattern/#3-entity-specific-tools","title":"3. Entity-Specific Tools","text":"<pre><code>class UsersTool extends EntityTool {\n  private apiClient: ApiClient;\n\n  constructor(apiClient: ApiClient) {\n    super();\n    this.apiClient = apiClient;\n\n    // Register operations\n    this.registerOperation('list', this.listUsers, listSchema);\n    this.registerOperation('get', this.getUser, getSchema);\n    this.registerOperation('create', this.createUser, createSchema);\n    this.registerOperation('update', this.updateUser, updateSchema);\n    this.registerOperation('delete', this.deleteUser, deleteSchema);\n  }\n\n  private async listUsers(params: ListUsersParams): Promise&lt;User[]&gt; {\n    const response = await this.apiClient.get('/users', params);\n    return response.data.map(userData =&gt; this.mapToUser(userData));\n  }\n\n  private async getUser(params: GetUserParams): Promise&lt;User&gt; {\n    const response = await this.apiClient.get(`/users/${params.userId}`);\n    return this.mapToUser(response.data);\n  }\n\n  private async createUser(params: CreateUserParams): Promise&lt;User&gt; {\n    const response = await this.apiClient.post('/users', params);\n    return this.mapToUser(response.data);\n  }\n\n  private async updateUser(params: UpdateUserParams): Promise&lt;User&gt; {\n    const response = await this.apiClient.put(`/users/${params.userId}`, params);\n    return this.mapToUser(response.data);\n  }\n\n  private async deleteUser(params: DeleteUserParams): Promise&lt;void&gt; {\n    await this.apiClient.delete(`/users/${params.userId}`);\n  }\n\n  private mapToUser(data: any): User {\n    // Convert API response to User entity\n    return {\n      id: data.id,\n      username: data.username,\n      email: data.email,\n      role: data.role,\n      properties: data.properties || {}\n    };\n  }\n}\n</code></pre>"},{"location":"best-practices/factory-pattern/#4-tool-registry","title":"4. Tool Registry","text":"<pre><code>class ToolRegistry {\n  private tools: Map&lt;string, EntityTool&gt; = new Map();\n\n  constructor(apiClient: ApiClient) {\n    // Initialize and register tools\n    this.registerTool('users', EntityToolFactory.createUsersTool(apiClient));\n    this.registerTool('resources', EntityToolFactory.createResourcesTool(apiClient));\n    // Register other tools...\n  }\n\n  public registerTool(name: string, tool: EntityTool): void {\n    this.tools.set(name, tool);\n  }\n\n  public async executeTool(name: string, args: any): Promise&lt;any&gt; {\n    const tool = this.tools.get(name);\n\n    if (!tool) {\n      throw new Error(`Tool '${name}' not found`);\n    }\n\n    try {\n      return await tool.execute(args);\n    } catch (error) {\n      // Enhanced error handling\n      throw this.enhanceError(error, name, args);\n    }\n  }\n\n  public getToolNames(): string[] {\n    return Array.from(this.tools.keys());\n  }\n\n  public getToolDocumentation(name: string): Documentation {\n    const tool = this.tools.get(name);\n\n    if (!tool) {\n      throw new Error(`Tool '${name}' not found`);\n    }\n\n    return tool.getDocumentation();\n  }\n\n  private enhanceError(error: any, toolName: string, args: any): Error {\n    // Add context to error\n    error.toolName = toolName;\n    error.args = args;\n    return error;\n  }\n}\n</code></pre>"},{"location":"best-practices/factory-pattern/#rest-api-integration","title":"REST API Integration","text":""},{"location":"best-practices/factory-pattern/#apiclient-implementation","title":"ApiClient Implementation","text":"<pre><code>class ApiClient {\n  private baseUrl: string;\n  private authToken: string;\n\n  constructor(baseUrl: string, authToken: string) {\n    this.baseUrl = baseUrl;\n    this.authToken = authToken;\n  }\n\n  async get(path: string, queryParams?: object): Promise&lt;any&gt; {\n    return this.request('GET', path, queryParams);\n  }\n\n  async post(path: string, data?: object): Promise&lt;any&gt; {\n    return this.request('POST', path, null, data);\n  }\n\n  async put(path: string, data?: object): Promise&lt;any&gt; {\n    return this.request('PUT', path, null, data);\n  }\n\n  async delete(path: string): Promise&lt;any&gt; {\n    return this.request('DELETE', path);\n  }\n\n  private async request(method: string, path: string, queryParams?: object, data?: object): Promise&lt;any&gt; {\n    try {\n      const url = new URL(this.baseUrl + path);\n\n      // Add query parameters\n      if (queryParams) {\n        Object.entries(queryParams).forEach(([key, value]) =&gt; {\n          url.searchParams.append(key, String(value));\n        });\n      }\n\n      const response = await fetch(url.toString(), {\n        method,\n        headers: {\n          'Authorization': `Bearer ${this.authToken}`,\n          'Content-Type': 'application/json',\n          'Accept': 'application/json'\n        },\n        body: data ? JSON.stringify(data) : undefined\n      });\n\n      if (!response.ok) {\n        throw await this.handleErrorResponse(response);\n      }\n\n      return await response.json();\n    } catch (error) {\n      throw this.enhanceNetworkError(error, method, path);\n    }\n  }\n\n  private async handleErrorResponse(response: Response): Promise&lt;Error&gt; {\n    let errorData: any;\n\n    try {\n      errorData = await response.json();\n    } catch {\n      errorData = { message: 'Unknown error' };\n    }\n\n    const error = new Error(errorData.message || `HTTP Error ${response.status}`);\n    error.statusCode = response.status;\n    error.responseData = errorData;\n\n    return error;\n  }\n\n  private enhanceNetworkError(error: any, method: string, path: string): Error {\n    error.request = { method, path };\n    return error;\n  }\n}\n</code></pre>"},{"location":"best-practices/factory-pattern/#pagination-support","title":"Pagination Support","text":"<pre><code>class PaginationHelper {\n  static async fetchAllPages&lt;T&gt;(fetchPage: (page: number) =&gt; Promise&lt;{data: T[], totalPages: number}&gt;): Promise&lt;T[]&gt; {\n    const result: T[] = [];\n    let currentPage = 1;\n    let totalPages = 1;\n\n    do {\n      const response = await fetchPage(currentPage);\n      result.push(...response.data);\n      totalPages = response.totalPages;\n      currentPage++;\n    } while (currentPage &lt;= totalPages);\n\n    return result;\n  }\n}\n</code></pre>"},{"location":"best-practices/factory-pattern/#schema-definition-examples","title":"Schema Definition Examples","text":""},{"location":"best-practices/factory-pattern/#zod-schema-examples","title":"Zod Schema Examples","text":"<pre><code>import { z } from 'zod';\n\n// User schemas\nconst listUsersSchema = z.object({\n  page: z.number().int().positive().optional(),\n  pageSize: z.number().int().positive().max(100).optional(),\n  filter: z.string().optional()\n});\n\nconst getUserSchema = z.object({\n  userId: z.string().uuid()\n});\n\nconst createUserSchema = z.object({\n  username: z.string().min(3).max(50),\n  email: z.string().email(),\n  role: z.enum(['admin', 'user', 'guest']).optional(),\n  properties: z.record(z.string(), z.any()).optional()\n});\n\nconst updateUserSchema = z.object({\n  userId: z.string().uuid(),\n  username: z.string().min(3).max(50).optional(),\n  email: z.string().email().optional(),\n  role: z.enum(['admin', 'user', 'guest']).optional(),\n  properties: z.record(z.string(), z.any()).optional()\n});\n\nconst deleteUserSchema = z.object({\n  userId: z.string().uuid()\n});\n</code></pre>"},{"location":"best-practices/factory-pattern/#complete-system-initialization","title":"Complete System Initialization","text":"<pre><code>function initializeSystem(baseUrl: string, authToken: string) {\n  // Create API client\n  const apiClient = new ApiClient(baseUrl, authToken);\n\n  // Create tool registry and register tools\n  const toolRegistry = new ToolRegistry(apiClient);\n\n  return {\n    // Execute a tool operation\n    async execute(toolName: string, operation: string, params: any) {\n      return toolRegistry.executeTool(toolName, {\n        operation,\n        [`${operation}Params`]: params\n      });\n    },\n\n    // Get list of available tools\n    getToolNames() {\n      return toolRegistry.getToolNames();\n    },\n\n    // Get documentation for a tool\n    getToolDocumentation(toolName: string) {\n      return toolRegistry.getToolDocumentation(toolName);\n    }\n  };\n}\n\n// Usage example\nconst system = initializeSystem('https://api.example.com', 'auth-token-123');\n\n// List users\nconst users = await system.execute('users', 'list', { page: 1, pageSize: 10 });\n\n// Create a user\nconst newUser = await system.execute('users', 'create', {\n  username: 'johndoe',\n  email: 'john@example.com',\n  role: 'user'\n});\n</code></pre>"},{"location":"best-practices/factory-pattern/#benefits-of-this-architecture","title":"Benefits of This Architecture","text":"<ol> <li> <p>Reduced Complexity: Instead of dozens of individual tools (one per operation), you have a handful of entity tools with multiple operations.</p> </li> <li> <p>Intuitive Organization: Tools are organized by the entities they operate on, making them more discoverable and easier to understand.</p> </li> <li> <p>Consistent Interface: All entity tools follow the same pattern for operations and parameters, providing a consistent user experience.</p> </li> <li> <p>Better Error Handling: Each entity tool can handle errors specific to its domain, providing more meaningful error messages.</p> </li> <li> <p>Enhanced Documentation: Entity tools can provide rich documentation with examples and operation-specific descriptions.</p> </li> <li> <p>Simplified Maintenance: Adding new operations to an entity is easier than creating entirely new tools.</p> </li> <li> <p>Testability: The architecture lends itself well to unit testing and dependency injection.</p> </li> </ol>"},{"location":"best-practices/factory-pattern/#implementation-guidelines","title":"Implementation Guidelines","text":"<p>When implementing this pattern:</p> <ol> <li> <p>Start with Domain Entities: Identify the key entities in your domain (Users, Resources, etc.).</p> </li> <li> <p>Define Operations: For each entity, define the operations it supports (list, get, create, etc.).</p> </li> <li> <p>Create Base Class: Implement a base class with common functionality for all entity tools.</p> </li> <li> <p>Implement Factory: Create a factory class with methods to create each entity tool.</p> </li> <li> <p>Create Registry: Implement a registry to manage tool registration and execution.</p> </li> <li> <p>Add Documentation: Provide rich documentation with examples and operation-specific descriptions.</p> </li> <li> <p>Handle Errors: Implement comprehensive error handling with meaningful error messages.</p> </li> </ol> <p>This architectural pattern provides a maintainable, user-friendly, and robust approach to implementing MCP servers with REST API integration.</p>"},{"location":"overview/book-introduction/","title":"Augmented Development: A Guide to Thoughtful AI Integration","text":""},{"location":"overview/book-introduction/#introduction","title":"Introduction","text":"<p>Welcome to a new era of software development. The tools at our disposal have evolved dramatically, and with them, our potential to create, innovate, and solve problems has expanded in ways that were science fiction just a few years ago. AI-powered coding assistants like GitHub Copilot, Cursor, Claude, and others have become increasingly sophisticated, offering capabilities that go far beyond simple autocompletion or code suggestions.</p> <p>But with these powerful new tools comes an important question: How do we integrate them thoughtfully into our development practices to enhance our work rather than complicate it?</p> <p>This book exists to address that question. It's not a technical manual for specific AI tools, which are evolving too rapidly for such documentation to remain relevant. Rather, it's a collection of principles, patterns, and practices for working effectively with AI coding assistants as collaborators in the development process.</p>"},{"location":"overview/book-introduction/#why-this-book-exists","title":"Why This Book Exists","text":"<p>I created this guide because I've seen both the transformative potential and the pitfalls of AI-assisted development. When used thoughtfully, these tools can:</p> <ul> <li>Accelerate development while maintaining or improving quality</li> <li>Reduce the cognitive load of routine coding tasks</li> <li>Enable developers to focus more on creative problem-solving</li> <li>Serve as learning tools that expose developers to new patterns and practices</li> <li>Help teams maintain consistency across large codebases</li> </ul> <p>However, without intention and structure, the same tools can lead to:</p> <ul> <li>Codebases with inconsistent styles and approaches</li> <li>Solutions that prioritize novelty over maintainability</li> <li>Development workflows that become fragmented and disjointed</li> <li>A false sense of productivity that masks underlying issues</li> </ul> <p>This book aims to help you maximize the benefits while avoiding the pitfalls.</p>"},{"location":"overview/book-introduction/#a-philosophy-of-augmentation-not-replacement","title":"A Philosophy of Augmentation, Not Replacement","text":"<p>The approach advocated throughout these pages is one of augmented development \u2013 using AI tools to enhance human capabilities rather than replace them. The most powerful development environments are those where humans and AI work together, each contributing their unique strengths:</p> <ul> <li>Humans excel at: Understanding context, setting priorities, making value judgments, creative problem-solving, and understanding the needs of other humans.</li> <li>AI excels at: Recalling patterns, generating alternatives, processing large volumes of information, and executing repetitive tasks with precision.</li> </ul> <p>When these strengths are combined effectively, the result is far more powerful than either working alone.</p>"},{"location":"overview/book-introduction/#how-to-use-this-book","title":"How to Use This Book","text":"<p>This guide is organized into three main sections:</p> <ol> <li>Best Practices: Patterns and approaches that enhance productivity and quality when working with AI assistants</li> <li>Antipatterns: Common pitfalls and problematic behaviors to watch for and avoid</li> <li>Implementation Guides: Practical examples and tools for integrating these concepts into your workflow</li> </ol> <p>You don't need to implement everything at once. In fact, I specifically recommend against trying to apply all these practices simultaneously. Instead:</p> <ol> <li>Start where you are: Review the antipatterns section and identify if any resonate with challenges you're currently facing</li> <li>Pick one practice: Choose a single best practice that addresses your most pressing need</li> <li>Experiment deliberately: Implement it as a controlled experiment with clear success metrics</li> <li>Reflect and iterate: Evaluate the results, adjust your approach, and then consider adding another practice</li> </ol> <p>This incremental approach aligns with established improvement frameworks like DORA (DevOps Research and Assessment) and CALMS (Culture, Automation, Lean, Measurement, Sharing), which emphasize the importance of measured, iterative improvement over wholesale transformation.</p>"},{"location":"overview/book-introduction/#a-rapidly-evolving-landscape","title":"A Rapidly Evolving Landscape","text":"<p>It's important to acknowledge that we're in the early days of AI-assisted development. The tools are evolving rapidly, sometimes weekly, with new capabilities and approaches emerging constantly. This guide focuses on principles that should remain relevant regardless of which specific tools you use or how they evolve.</p> <p>That said, the most successful teams will be those that maintain an experimental mindset, continuously exploring how new capabilities can be integrated into their workflow while staying grounded in software engineering fundamentals.</p>"},{"location":"overview/book-introduction/#the-art-of-constraint","title":"The Art of Constraint","text":"<p>Throughout this book, you'll notice an emphasis on thoughtful constraints rather than unlimited possibilities. This is intentional. As with any creative medium, software development often benefits from deliberate constraints that focus energy and attention.</p> <p>Just as an artist might choose a limited color palette to create a more cohesive work, a development team might select specific patterns for AI interaction that promote consistency and quality. The goal isn't to use every feature of AI assistants, but to use the right features in the right ways to enhance your specific development context.</p>"},{"location":"overview/book-introduction/#a-collaborative-journey","title":"A Collaborative Journey","text":"<p>This guide represents my current understanding of effective practices for AI-assisted development, but it's far from the final word. The field is evolving rapidly, and our collective understanding will grow through shared experimentation and open discussion.</p> <p>I encourage you to approach these recommendations with a scientific mindset: - Form hypotheses about how these practices might benefit your team - Test them in controlled ways - Measure the results - Share what you learn</p> <p>By contributing to our collective knowledge, you'll help shape how these powerful tools are integrated into the craft of software development for years to come.</p> <p>Let's begin this journey of augmented development \u2013 not by replacing what makes human developers valuable, but by enhancing those uniquely human capabilities with thoughtfully applied AI assistance.</p> <p>Welcome to the future of development. It's not about AI or humans. It's about AI and humans, working together in ways that make both more effective than either could be alone.</p>"}]}